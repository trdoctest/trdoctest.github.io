---
layout: tutorial
title:  "4. Ders: İşlem"
author: Taylan Özgür Bildik
excerpt: "Eğitimin giriş aşamasını gerçekleştirerek, GNU/Linux sistemini tanıyoruz."
tags: [Linux , çekirdek , kernel , linus torvalds , gnu , gpl , açık kaynak , özgür yazılım , unix , dağıtım]
categories: [egitimserisi, temel_linux]
tutorial: [4] 
---

# 18- İşlem Yönetimi

Bu bölümde "process" olarak geçen "işlem" kavramının anlaşılması ve yönetilebilmesi üzerinde duracağız. Öncelikle isim tanımı ile başlayacak olursak. Kimi zaman "process" terimi için Türkçe olarak "süreç" ifadesi hatta doğrudan "proses" kullanılsa da, terimin yapısı gereği "işlem" ifadesi daha doğru bir tanımlama olacaktır. Ben de anlatımlar sırasında "process" kavramı için "işlem" ifadesini kullanıyor olacağım. Bu açıklamayı, harici Türkçe kaynaklara göz attığınızda "işlem" yerine "süreç" ya da "proses" ifadeleriyle karşılaşmanız halinde herhangi bir karışıklık yaşamamanız için kısaca dile getirmek istedim. 


ℹ️ Hatırlatma**:** Anlatımlara geçmeden peşinen söyleyeyim; Buradaki anlatımları yalnızca temel sistem yönetimi kapsamında ele alıyor olacağız. Daha fazla detay için elbette işletim sistemi özelinde harici kaynaklara(işletim sistemi nasıl çalışır? işletim sistemi nasıl programlanır ? vb.) kaynaklara göz atabilirsiniz. Anlatımlar sırasında mümkün oldukça temelden başlayıp konu bağlamından uzaklaşmamaya ve gerekli olan bilgileri aktarmaya özen göstereceğiz. Yani aslında anlatımların herkes tarafından kolay takip edilebilir olması için Linux'ta bash kabuğu üzerinden işlemlerin nasıl yönetilebileceği hakkında fikir edinmeye çalışacağız.


Bu bölümün sonunda, şu ana kadar ele aldığımız ve ileride ele alacağımız pek çok kavramın bizler için daha anlamlı hale geleceğini umuyorum. Çok ayrıntılı olmasa da **genel işleyişi kavramamıza yardımcı olacak temel bilgilere** değiniyor olacağız. O halde daha fazla vakit kaybetmeden, anlatımlara "işlem" yani "process" olarak geçen kavramın tanımı ile başlayabiliriz.

## İşlem(Process) Nedir?

Oldukça genel bir tanımla, söz konusu işletim sistemleri olduğunda; diskimiz üzerinde mevcut bulunan ve sistemin çalıştırabileceği yapıda olan her türlü programın öncelikle RAM yani hafızaya yüklenmesi ve oradan da sırası geldiğinde CPU yani işlemci üzerinde işlenmesine bütüncül olarak "***process***" yani "***işlem***" diyoruz. Tanımı daha anlaşılır kılmak adına bahsi geçen temel kavramları kısaca açıklayabiliriz.

**Program:** herhangi bir yazılım dili ile yazılmış ve makine kodu olarak derlenmiş olan talimatlar dizisine verilen genel isimdir. Örneğin bash kabuğu C dili ile yazılmış ve derlenmiş olan bir programdır. Yani aslında bizler bash kabuk programını çalıştırırken, makine kodundan oluşturulmuş talimatlar dizisi işlemci tarafından işleniyor.

**Makine Kodu:** 2'li sayı sistemi(binary) ile yani 0 ve 1 rakamları ile oluşturulmuş, işlemciler tarafından anlaşılabilen ve işlenebilen dildir. Bizler yüksel seviyeli olarak geçen "python", "java", "C" ve benzeri diller ile programlarımızı yazarız ancak bu dilleri işlemcimiz doğrudan anlamlandıramaz. Çünkü yüksek seviyeli diller insanların kolay okuyup yazabileceği yapıdadır. Makine kodundan, biz insanların daha rahat okuyup anlayabileceği düzeye yaklaştıkça dilleri yüksek seviyeli olarak adlandırıyoruz. Yani buradaki yükseklik ifadesi bir üstünlük göstergesinden ziyade makine koduna oranla insanların daha rahat kavrayabileceği insana daha yakın olan dilleri kast ediyor. Dolayısıyla yüksek seviyeli diller ile programladığımız talimatların, işlemcinin anlayacağı dil olan düşük seviyeli makine diline dönüştürülmesi gerekir. Dönüştürme işleminde de "derleyici" ve "yorumlayıcı" olmak üzere 2 temel yaklaşım vardır. Kısaca açıklamamız gerekirse;

**Derleyici:** Tüm komutları okuyup optimizasyonu yaparak işlemcinin çalıştırabileceği şekilde makine koduna dönüştürür. Daha önce C dili ile yazılmış program dosyalarının kaynak koddan derlenerek kurulabilmesi için gcc derleyicisini kullanmıştık hatırlarsanız. Yani aslında vurgu yapmadık ama bizler de bizzat derleme işlemini uyguladık. 

**Yorumlayıcı:** Komutları satır satır okuyup sırasıyla yorumlayarak işlemci tarafından anlaşılır hale getirilmesini sağlıyor. Yorumlayıcılar tek seferde kodun tamamına bakmıyor, kodun parça parça dönüştürülmesini sağlıyor. Derleyicilere oranla bu yöntemde kodun genelinde iyileştirme yapılamadığı için komutlar kısmen daha verimsiz çalışıyor. Ancak kabuk dili gibi anlık olarak komutların yorumlanması gereken durumlar için yorumlayıcı özelliği harika bir çözüm sunuyor. Sistemi komut girerken kullanmakta olduğumuz Bash kabuğu da yorumlayıcı yapıda bir dil olduğu için kullanıcıdan gelen komutları satır satır okuyup değerlendiriyor.

Sistem yönetimi için kullandığımız bash kabuğu hem etkileşimli kullanım hem de programlanabilirlik sunduğu için yorumlayıcı yapıda olması makuldür. Yorumlayıcı yapısı sayesinde konsola bir komut girdiğimizde bu komut anında işlenir. Veya bir dosya içine kabuk komutlarını uygun şekilde yazıp programlama yaptığımızda bu dosya çalıştırılırken de kabuk komutları anında işlenir. Ek olarak derleme işlemi ile uğraşmayız, dosya içindeki komutların hepsi sırasıyla tek tek çalıştırılır. Kabuk özelinde bu konunun daha fazla ayrıntısına şu an için ihtiyacımız yok. Ancak işlem dediğimiz olgunun temelde hangi aşamalardan geçtiğine kısaca değinmek üzere temel bileşenleri açıklayarak devam edebiliriz.

Örneğin firefox tarayıcısını açmak için kabuğuma firefox komutunu girdiğimde kabuk programı, yazdığım komutu yorumlayıp firefox programı diskte yüklü ise bulup başlatılmasını sağlıyor. 

Firefox programının başlatılabilmesi için yani sistem üzerinde aktif çalışmakta olan bir işlem halini alabilmesi için sırasıyla disk > ram > cpu aktarım aşamalarından geçmesi gerekiyor. Şimdi kısaca bu aktarım yolu üzerindeki bileşenleri açıklayacak olursak;

![https://web.stanford.edu/class/cs101/software-program.png](https://web.stanford.edu/class/cs101/software-program.png)

**Disk:** Programlar gibi sistem için gerekli olan dosyaları bünyesinde bulunduran kalıcı depolama birimidir. Nitekim disk yönetimi bölümünde bu konudan uzun uzun bahsettik. Yani aslında diskin ne olduğunu biliyorsunuz.

Biraz önceki anlatımlardan programların, aslında makine kodu talimatlarını içeren dosyalar olduğunu da biliyorsunuz. Disk, bunları kalıcı olarak depolamaktan sorumlu birimdir. Bir programın dosyalarına ihtiyaç olduğunda diske bakılır.

![https://web.stanford.edu/class/cs101/software-cpu.png](https://web.stanford.edu/class/cs101/software-cpu.png)

**RAM:** Disk üzerinde yer alan çalıştırılmaya uygun şekilde derlenmiş olan programların(yani makine kodu talimatlarının) işlemci tarafından işlenmek üzere geçici olarak hafızada tutulmasını sağlar. Diskteki verilerin doğrudan işlemciye aktarılmayıp RAM'e aktarılmasının en temel nedeni RAM'in sağladığı hızdır. RAM'in, verileri kalıcı olarak kaydetme ve saklama zorunluluğu bulunmadığı için programlara ait talimatlar dizisini çok hızlı şekilde alıp işlemciye aktarabiliyor. İşi biten talimatlar da RAM üzerinden siliniyor. Yüksek hızlı aktarım sayesinde yüksek işlem kapasitesi sağlanabiliyor.

**CPU:** Program dosyaları içerisinde bulunan işlem emirlerini yerine getirmek üzere, RAM üzerinde yer alan programın makine kodu talimatlarını okuyup uygun şekilde işliyor. 

![https://web.stanford.edu/class/cs101/software-program-run.png](https://web.stanford.edu/class/cs101/software-program-run.png)

En nihayetinde disk üzerindeki programımız bir işleme dönüştürülmüş oluyor. Bizler de işletim sistemi üzerinden bu işlemi yönetebiliyoruz.

Netleştirmek için son olarak program ile işlemin farkını tek cümlede özetleyecek olursak; Program, belirli görevleri yerine getirmek için tasarlanmış bir dizi makine kodu talimatı içerir. Programlar, gerektiği zaman tekrar tekrar çalıştırılabilmeleri için disk üzerinde kalıcı olarak tutulur. İşlem ise programın hafızaya(RAM) yüklenip işlemci tarafından çalıştırılmasıdır. 

Programların işleme dönüşümünün en yalın hali bahsettiğimiz şekildedir. Bu detayları(hatta çok çok daha fazlasını) biliyor ya da bilmeseniz de buradaki düzeyde açıklanmış olmasını gereksiz buluyor olabilirsiniz. Yine de anlatımın herkes tarafından sıralı ve kolay takip edilebilir olması için çok kısa da olsa temel yapıdan bahsetmeye gayret ediyorum.

![18-%20I%CC%87s%CC%A7le%2075bff/Untitled.png](18-%20I%CC%87s%CC%A7le%2075bff/Untitled.png)

Neticede en genel hatlarıyla işlemin ne olduğunu öğrenmiş olduk. Şimdi Linux yani işletim sistemi özelinde işlemlerin nasıl oluştuğuna da çok kısaca değinerek ihtiyacımız olan temel bilgi tabanını oluşturmaya devam edelim.

# GNU/Linux Üzerinde İşlemlerin Oluşumu

Öncelikle ilk işlemin nasıl ve neden oluşturulduğunu anlayabilmek için sistemin açılışına kısaca değinebiliriz. Disk yönetimini ele alırken de açılışın bir kısmından bahsetmiştik zaten. Yine kısaca işlem özelinde ele alacak olursak; GNU/Linux'ta, tipik önyükleme işleminde birkaç temel aşama vardır.

1. İlk aşama **BIOS veya daha modern cihazlarda UEFI'dir.** : Bios ya da uefi, bilgisayarımızı ilk açtığımızda donanım kontrolü gerçekleştiriyor. Eğer donanımlarda sorun yoksa ilk sıradaki diskten başlayarak, MBR ya da GPT disk bölümleme tablolarını kontrol ediyor.
2. **MBR ya da GPT** : Mevcut diskteki bölümler hakkında bilgi tutan tablolardır. İşletim sistemi çekirdeğinin önyüklenebilmesini sağlayan boot looder yani önyükleyici yazılıma da bu tablolar üzerinden ulaşılıyor. Elbette söz konusu yazılım olduğunda diğer pek çok yazılım gibi önyükleme yazılımının da pek çok alternatifi var. Yine de birden fazla önyükleyici yazılım alternatifi olsa da en yaygını GRUB yazılımıdır. Neticede diskte mevcutsa önyükleyici yazılım başlatılıyor.
3. **GRUB** : GRUB yazılımı işletim sistemlerinin önyüklenebilmesini sağlıyor. Eğer birden fazla işletim sistemi mevcutsa bunlar listeli şekilde karşımıza çıkıyor. Biz hangi işletim sistemini başlatmak istiyorsak onu seçebiliyoruz. Eğer daha önce dualboot olarak mevcut işletim sisteminizin yanına Linux kurduysanız GRUB menüsünde işletim sistemlerinin sıralandığını da görmüşsünüzdür. Tek yapmanız gereken bu listeden önyüklemek istediğiniz işletim sistemini seçmek. Buradan Linux'u seçtiğinizde Linux çekirdeği GRUB tarafından önyükleniyor. 
4. **KERNEL** : Çekirdek uygun şekilde başlatıldıktan ve dosya sistemi bağlandıktan sonra ilk işlem olan init işlemi çekirdek tarafından başlatılıyor.
5. **INIT** : Init sistemin çalışması için gerekli olan temel servisleri ve hizmetleri başlatmakla görevli yazılımdır. init yazılımı olarak kullanılan pek çok alternatif yazılım olsa da modern sistemlerde systemd init yazılımı olarak sıklıkla karşımıza çıkıyor. Modern debian ve redhat dağıtımları da systemd yazılımını tercih ediyor. Sistemin ihtiyaçlarına göre başlatılacak servis ve hizmet değişebilir bu sebeple init daha önceden belirtilmiş olan runlevel yani çalışma seviyesine göre gerekli işlemlerin başlatılmasını sağlıyor. Yani çekirdek ilk işlem olan init i başlatır, init ise sistemin çalışması için gereken tüm temel servis ve hizmetlerin başlatılmasına aracılık eder. Bu noktada, artık işletim sistemi başlatılmıştır. 
6. **RUNLEVEL** : Runlevel ifadesi daha sonra da ayrıca bahsedeceğimiz şekilde sistemin başlatılacağı çalışma seviyesini ifade ediyor. init yazılımı tarafından farklı çalışma seviyesinde farklı hizmet ve servisler başlatılıyor. Farklı çalışma seviyeleri sayesinde sistem tam olarak ihtiyaç duyulan servis ve hizmetler ile başlatılabiliyor. Örneğin sistemi kurtarma seviyesinde başlatırsak yalnızca kurtarma için gerekli olan işlemler başlatılarak sistemi kolayca kurtarabilmemiz mümkün oluyor. Zaten bu konudan ayrı bir bölümde bahsedeceğiz, o yüzden bu kadarlık bilgi şimdilik yeterli.

Böylelikle Linux sisteminin nasıl başlatıldığını kafanızı karıştırabilecek detaylar olmadan yalın şekilde özetlemiş olduk. Eğer daha fazla detayı merak ediyorsanız kısa bir araştırma ile tüm önyükleme süreci detaylarına ulaşabilirsiniz.

Çok kısaca açıkladığımız tipik önyükleme işleminin ardından ilk işlem olan init hakkında biraz daha ayrıntıya değinebiliriz.

Çekirdeğimiz ilk işlem olan ana işlemi yani "init" işlemini başlatıyor dedik. init, sistem başlangıcında çalıştırılması gereken işlemlerin başlatılmasından sorumlu yazılımdır. Zaten "init" ismi "initialization" yani "başlatma" ifadesinin kısaltmasından geliyor. init yazılımı sistemin açıldığı çalışma seviyesine göre daha önceden belirlenmiş olan hizmet ve servislerin yani çeşitli işlemlerin başlatılmasına öncülük ediyor. Yani aslında init, işlem hiyerarşisinde ata işlemdir. Normalde her işlem doğrudan veya dolaylı olarak init altında başlatılır. Peki ama bu tam olarak ne demek oluyor ?

Sistemin yapısı gereği, çekirdeğin başlattığı init işlemi hariç, yeni bir işlem başlatılabilmesi için mevcut işlemin çekirdeğe fork( ) ve exec( ) sistem çağırısında bulunması gerekiyor. Netleştirmek için açıklamaya devam edelim.

Örneklendirecek olursak, diyelim ki init işlemi çalıştıktan hemen sonra bash kabuğunun başlatılmasını istedi. Bash kabuğunun başlatılması için bash kabuğunun yeni bir işlem olarak çalıştırılması gerekiyor. İşlemleri çekirdek yönettiği için yeni işlem oluşturma isteğinin çekirdeğe ifade edilmesi gerekiyor. Çekirdek ile iletişim kurmak için de sistem çağrıları kullanıyor. Bu sebeple yeni işlem oluşturmak için init işlemi, çekirdeğe çatallama olarak geçen fork( ) sistem çağrısında bulunuyor. Çatallama çağrısı sonucunda mevcut init işleminin **birebir kopyası olan** yeni bir işlem oluşturuluyor ve yeni işleme benzersiz bir işlem numarası(pid) tanımlanıyor. İşlem numaraları sayesinde ana işlem ve oluşturulan yeni alt işlem kolaylıkla ayırt edilip yönetilebiliyor. 

![]({{ site.url}}/egitimserisi/img/18-%20I%CC%87s%CC%A7le%2075bff/Untitled%201.png)

Ancak tüm süreç bununla sınırlı değil. Çünkü yeni bir işlem oluşturulmuş olsa bile, çalıştırmak istediğimiz yeni programın yani bash programının makine kodu talimatları, oluşturulan yeni işleme henüz aktarılmadı. Oluşturulan yeni alt işlem init işleminden kopyalanarak oluşturulduğu için hala init'in makine kodu talimatlarına sahip. Bu noktada çatallanmış olan işleme, çalıştırılmasını istediğimiz program yani bash programının talimatlarının tanımlanabilmesi için exec( ) sistem çağırısı yapılıyor. 

![]({{ site.url}}/egitimserisi/img/18-%20I%CC%87s%CC%A7le%2075bff/Untitled%202.png)

Böylelikle init işleminden kopyalanan program talimatlarının yerini bash kabuk programının talimatları alıyor. En nihayetinde bash programının makine kodu talimatlarını içeren ve benzersiz işlem numarasına sahip yeni bir işlem oluşturulmuş oluyor. İşte Linux üzerinde yeni bir işlem oluşturmanın en yalın hali bu bahsi geçen süreçtir. Tüm süreci en yalın haliyle ele almaya çalıştım ancak yine de biraz karmaşık geldiyse endişelenmeyin. Anlatımın devamında tüm kavramlar yerli yerine oturmuş olacak.

Çok temel düzeyde işlemlerin oluşturulma yapısından bahsettik. Şimdi de anlattıklarımızı somutlaştırmak üzere sorgulamaya devam edelim. Öncelikle ilk oluşturulan işlemin gerçekten init olup olmadığını teyit ederek başlayabiliriz. İlk oluşturulan ana işlemin hangisi olduğunu teyit etmek için konsola `ps -A | head -2` komutunu girebilirsiniz. Buradaki ps aracının ismi proccess status yani işlem durumu ifadesinin kısalmasından geliyor. Bu araç sayesinde çalışmakta olan işlemlerin durumlarını konsol üzerinden takip edebiliyoruz. A seçeneği sayesinde de çalışmakta olan tüm işlemleri alıp, head komutu ile ilk 2 satırı filtrelemiş olduk. Bu sayede tüm işlemler yerine yalnızca çıktıların başlığıyla birlikte ilk işlemi konsola bastırmış olduk. Bakın aldığımız çıktıda PID(process id) yani işlem numarası "1" olan işlemin "systemd" olduğunu görebiliyoruz. 

Hatta ilk işlemin init işlemi olduğunu teyit etmek için ps aracının f seçeneğini de komutumuza ekleyebiliriz. Bakın aldığımız çıktıda /sbin/init dosyasının ilk işlem olarak çalıştırıldığını görebiliyoruz. Bu init dosyası sistemdeki init yazılımının çalıştırılmasını sağlıyor. Bu yazılım benim sistemim için systemd yazılımı. Bu dosya aslında çalıştırılacak olan init yazılımı için bir sembolik link. Bu durumu görmek için ls -l /sbin/init komutunu kullanabiliriz. Bakın init dosyası aslında benim sistemimde systemd dosyasına bağlı. Yani benim sistemimde ilk çalıştırılan init işleminin systemd yazılımı olduğunu bir kez daha teyit etmiş oldum. 

Ancak daha önce de bahsettiğimiz şekilde sizin kullanmakta olduğunuz sistem, init yazılımı olarak systemd kullanmıyor da olabilir. Yani burada farklı bir çıktı da almış olabilirsiniz. Ancak neticede ilk işlemin init yazılımına ait işlem olduğunu ve bu işlemin işlem numarasının 1 olduğunu görmüş olduk. İşlemlere tanımlanan işlem numaraları, çekirdek için "0" olarak kabul edilip sıralı şekilde atandığından, "1" numaralı işlem ilk başlatılan işlemi yani "init" işlemini temsil ediyor. Daha sonraki tüm işlemler de zaten init işlemi altında oluşturulan alt işlemlerdir. Alt işlemler sırasıyla boştaki işlem numaraları ile numaralandırılıyor. İşlem numaraları sayesinde de işlemleri kolayca takip edip yönetebiliyoruz. 

İlk başlatılan işlemin init olduğunu bizzat teyit ettiğimize göre şimdi de bahsetmiş olduğumuz işlem hiyerarşisi konusunda açıklık getirmek istiyorum.

Açıklama yapabilmek için işlemleri hiyerarşik şekilde sunan pstree aracını kullanmak istiyorum. Daha önce dosya sistemi hiyerarşisinden bahsederken ağaç benzetmesini kullanmıştık. İşlem hiyerarşisi de benzeri şekilde ağaç gibi dallara ayrıldığı için pstree aracı isminden de anlaşılabileceği gibi bizlere işlemleri hiyerarşik düzende sunuyor. Çıktılar üzerinden konuşmak üzere öncelikle pstree komutunu girelim. Eğer sizde pstree aracı yüklü değilse paket yöneticisi üzerinden kolayca yükleyebilirsiniz, nasıl yükleyebileceğinizi zaten biliyorsunuz. Örneğin Ubuntu için sudo apt install pstree -y komutunu kullanmam yeterli.  

Bakın bütün işlemler systemd yani init işlemi altında hiyeraşik olarak başlatılmış şekilde gözüküyor. İlk olarak systemd başlatılmış daha sonra systemd altında başka işlemler ve bu işlemlerin altında da daha başka işlemler hiyerarşik düzende başlatılmış. Zaten pstree komutu da ağaç gibi olan bu işlemlerin hiyerarşik durumunu görmemizi sağlıyor.

Bu çıktılara bakarak anlatımın başında bahsetmiş olduğumuz işlemlerdeki hiyerarşik düzeni aslında bizzat teyit edebiliyoruz. Örneğin bakın systemd işlemi altında gnome terminal, onun altında bash ve onun da altında pstree aracı çalıştırılmış şekilde gözüküyor. Çıktılar basılmadan önce en son pstree komutunu girdiğim için bash kabuğu altında pstree işlemi de çalıştırılmış şekilde gözüküyor. Yani bu çıktılar komutun girildiği andaki işlem durumlarını hiyerarşik olarak sunuyor. Tüm çıktıları aldığımız için okuması biraz güç. 

İstersek ps f komutu ile tüm işlemler yerine yalnızca mevcut kabukta çalışmakta olan işlemlerin durumunu da hiyerarşik şekilde bastırabiliriz. Bakın bash kabuğu altında ps f işlemi çalıştırılmış olarak gözüküyor. Biz ps f komutunu girdiğimiz andaki işlem durumları alındığı için ps f işlemi de çıktı olarak bastırıldı. Buradaki çıktıda yer alan diğer işlemler grafiksel arayüzle ilgili şimdilik bunlara takılmayın ama görebildiğiniz gibi bu işlemeler de hiyerarşik düzende. Bu hiyerarşik düzende özellikle aksi belirtilmediği sürece bash kabuğu ps aracının işini tamamlamasını beklerken, şu an çıktıda gözükmese de terminal aracı da yeni bir komut almak veya kapanmak için bash kabuğunun işini bitirmesini bekliyor ve bu şekilde hiyerarşisinin en üstündeki init işlemine kadar tüm alt işlemler üst işlemleri tarafından bekleniyor yani hiyerarşik yapı gereği alt işlemler üst işlemlere bağımlı. Örneğin init işlemi sonlandırılırsa altındaki tüm alt işlemler de otomatik olarak sonlandırılır. Daha net anlaşılabilmesi için ağaç örneğimize tekrar dönecek olursak ana dalı kestiğimizde küçük dalları da aslında ağaçtan koparmış oluyoruz değil mi ? İşte bu sebeple aksi belirtilmediği sürece ana işlem ölürse ona bağımlı olan alt işlemler de otomatik olarak öldürülüyor. Bu konudan tekrar bahsedeceğiz, ancak daha fazla bahsetmeden önce işlemlerdeki çocuk ve ebeveyn kavramlarını da kısaca açıklamak istiyorum.

Ben şu ana kadar anlatımlar sırasında hep "alt işlem", "üst işlem" kavramlarını kullandım ancak burada bahsi geçen alt işlemler "child process" yani "çocuk işlem" olarak isimlendirilirken, alt işlemi oluşturan üst işlemler de "ebeveyn" yani "parent process" olarak ifade edilebiliyor. Elbette bu bağlamda ana işlem çocuk işlemleri doğurabileceği gibi çocuklar da zamanı geldiğinde kendi çocuk işlemlerini doğurarak alt işlemleri için ebeveyn olabiliyorlar. İşlemlerin hiyerarşik çıktılarında da bu durumu bizzat gördük. Zaten burada bahsi geçen çocuk ve ebeveyn gibi isimlendirmeler de yapının kolay kavranması için tercih edilen soyutlamalardır. 

Tamamdır ebeveyn ve çocuk kavramlarından da bahsettik. Şimdi tekrar konumuza dönecek olursak standart yapıda ebeveyn işlem, aksi belirtilmediği sürece çocuk işlemin işini bitirmesini bekliyor. Yani, ebeveyn wait( ) sistem çağrısı ile çocuk işlemden gelecek exit( ) çağrısının sonucunu bekliyor. Başlatılan çocuk işlem sona erdiğinde, ebeveyn işlem exit( ) sistem çağrısı sayesinde çocuk işlemin sona erdiğini öğrenmiş oluyor. Bu sayede artık çocuk işlemi beklemesine gerek kalmadığını biliyor ve kendi işine devam edebiliyor. Üstelik döndürülen çıkış koduna(exit code) göre, çocuk işlemin başarılı olup olmadığından da haberdar oluyor. Çıkış kodları bizim için özellikle kabuk programlama yaparken önem kazanıyor. Örneğin bir işlemin sonucu olumlu ise x işlemi çalıştırılsın olumsuzsa y işlemi çalıştırılsın gibi koşullar belirtmek için kabuk programlamada bizzat çıkış kodlarına ihtiyacımız oluyor. Eğer kabuk programlamayla ilgilenirseniz bu durumu sizler de görebilirsiniz. 

![18-%20I%CC%87s%CC%A7le%2075bff/Untitled%203.png](18-%20I%CC%87s%CC%A7le%2075bff/Untitled%203.png)

Peki neden tüm kavramlardan ve bu yapıdan bahsettik? Yani fork exec wait exit çağrılarından neden bahsettik, bunlar sistem yöneticisi olarak bizim ne işimize yaracak ? Neticede sistem programlama yapmıyoruz? demiş olabilirsiniz ancak bence bu kavramlardan bahsetmek eğitim boyunca ele aldığımız tüm yapıyı daha net kavramamıza yardımcı olacağı için önemli. Yalnızca bu eğitimi düşünmeyin lütfen. Burada, eğitimin başında da söylediğim gibi daha fazla araştırma yapmak isteyenler için bir başlangıç noktası olmaktan bahsediyorum. Hatta daha somut olması için neden işlem yönetim komutlarına geçmeden önce bu kavramlardan bahsettiğimi örneklemek istiyorum.

Örneğin ileride arkaplanda işlem başlatacağız ve bu işlemi yaparken aslında ebeveyn işleme çocuk işlemi beklememesi gerektiğini söylemiş olacağız. 

Ya da örneğin, çocuk süreç sonlanmış olmasına rağmen ebeveyn süreç çocuğun exit çıktısını wait işlem çağrısı ile almadıysa çocuk işlem zombi olarak işlem tablosunda yer işgal etmeye devam edecek. Zombi işlemler işi bittiği için aktif olarak cpu ve ram gibi sistem kaynaklarını kullanmasa da işlem yönetimi konusunda karmaşa yaratır ve sınırlı sayıda olan işlem tablosunu boş yere işgal edebilir. 

Ayrıca başka bir durumu örnek olarak, bir çocuk işlemin ebeveyn işlemi çocukları beklemeden sonlandığında çocuk işlemler yetim kalabilir. Bu durumda ebeveyn işlem sonlandığı için artık çocuk işlemin exit çıktısını wait çağrısını ile alacak kimse kalmamıştır. Bu noktada zombi işlemleri önlemek adına init düzenli olarak wait çağrısında bulunarak sonlanmış olan yetim işlemleri evlat edinip çıkış kodları alır ve yetim işlemleri işlem tablosundan siler. 

Bu yaklaşımların detaylarına girmeyeceğim ancak bakın şimdiye kadar açıkladığımız temel kavramlar sayesinde işleyişi kolayca kavrayabiliyoruz. Yani temel kavramları bilerek Linux üzerindeki işlem yönetim mekanizması hakkında daha somut ve kalıcı bilgiye sahip olabiliyoruz. Elbette bu eğitimde tüm işlem mimarisinden ve işleyişinden bahsetmemiz mümkün değil. Daha fazlası için sistem programlama ya da işletim sistemleri nasıl çalışır gibi konular hakkında yazılmış kitaplara ve eğitimlere bakabilirsiniz. Yine de biz temel düzey için gerekli olan basit yapılardan mümkün olduğunda yalın şekilde bahsetmeye gayret ediyoruz. 

Sanırım lafı yine çok uzattım. Neticede sistemin genel işlem oluşturma yapısına değindiğimize göre şimdi bash kabuğu özelinde işlemlerin nasıl ele alındığına daha yakından bakabiliriz.  

## Bash Kabuğunda İşlemlerin Oluşumu

Bash kabuğu da en nihayetinde kendisinden önce başlatılmış olan bir işlemin çatallanması ve exec ile bash kabuk programının yeni işlem olarak çalıştırılması ile var oluyor. Bizler de bash kabuğuna komutlar vererek, bash kabuğu altında, programlar için işlemlerin oluşturulup çalıştırılmasını sağlamış oluyoruz. 

Ayrıca bash kabuğuna verilmiş olan komutların türüne göre işlem oluşturma davranışı da değişebiliyor. 

Bash, kendi bünyesinde bulunan yerleşik komutları(`cd`,`bg`,`echo`.. vs.) alt işlem oluşturmaya ihtiyaç duymadan geçerli kabuk işleminde çalıştırır. Çünkü bu komutlar aslında bash programının bir parçası olarak kabuk programına tahsis edilmiş olan işleme dahildirler. Dolayısıyla yeni bir işleme ihtiyaç olmadan, mevcut kabuk işlemi üzerinde çalıştırılırlar. Yeni işlem oluşturma zahmetine girilmediği için de dahili komutlar harici komutlara oranla daha hızlı çalışırlar. Kabuğun dahili komutları temel görevleri yerine getirmek için bulunması gereken en temel araç setini sağlar. 

Harici olan programlar bash kabuğu üzerinden çalıştırıldığında, bash kabuk programının bir parçası olmadıkları için; mevcut işlemin çatallanması ile oluşturulan kopya işlemdeki program talimatları,               exec çağrısı ile çalıştırılacak programın talimatları ile değiştirilir. Yani bash kabuğuna dahil olmayan araçlar kabuğun altında yeni bir çocuk işlem oluşturulup burada çalıştırılabilirler. Örneğin bizim anlatım sırasında kullanmış olduğumuz `ps` komutu aslında harici bir programdır. Eğer sistemde yüklü ise `ps` programının çocuk işlem üzerinden çalıştırılmasına bash kabuğu yalnızca aracılık eder. ps aracını çalıştırmak üzere kabuğa emir verdiğimizde bash kabuğu yalnızca bu aracı PATH yolu üzerinde arar bulursa çalıştırılması için kabuğa çağırıda bulunur. Çekirdek de mevcut bash kabuk işlemi çatallar ve exec ile ps program talimatlarını, çatallanmış olan bash program talimatlarının yerine koyar. Böylelikle bash kabuğu altında ps harici programı çocuk işlem olarak çalıştırılmış olur.

Bash kabuğu kendi bünyesinde bulunan dahili komutları mevcut kabuk işleminin devamı olarak doğrudan çalıştır. Ancak harici araçların bash kabuğu üzerinden çalıştırılması talep edildiğinde, fork ve exec sistem çağrıları ile ilgili araç alt işlemde çalıştırılır. Bu sebeple dahili komutlar harici komutlara oranla daha performanslı şekilde çalışır. Çünkü dahili(yerleşik-builtin) komutlar için her defasında fork ve exec sistem çağrıları ile mevcut işlem kopyalanıp bu işleme yeni program talimatları yüklenmesi gerekmez, yalnızca mevcut bash işleminin devamı olarak yürütülürler.

Bash kabuğunda yerleşik olan komutları görmek için compgen -b komutunu kullanabiliriz. Buradaki komutların yani aslında araçların hepsi bash kabuğunda yerleşik olarak bulunan araçlardır. Yani bash kabuğunun güncel sürümlerinin bulunduğu tüm sistemlerde bu araçları kullanabilirsiniz. 

İşlemlerden, işlemlerde ebeveyn-çocuk ilişkisinden ve bash üzerinden çağırılan araçların işlem oluşturma davranışlarından bahsettik. Bash üzerinde yerleşik olan araçların yeni işlem oluşturmadığını, harici olan araçların alt işlemde çalıştırıldığını artık biliyoruz. Peki ya daha önce hiç alt-kabuk(subshell) diye bir kavram duymuş muydunuz ? Alt kabuk kavramı genellikle alt işlem olarak çalıştırılan çocuk işlem ile karıştırılan bir kavramdır. Karışıklığı önlemek adına gelin altkabuk kavramını açıklayarak devam edelim.

Alt kabuklar hakkında; Betik dosyalarının, parantez içerisine yazılan komutların ve pipe işaretinin

[https://unix.stackexchange.com/a/442704/364572](https://unix.stackexchange.com/a/442704/364572)

[https://unix.stackexchange.com/questions/393349/difference-between-subshells-and-process-substitution](https://unix.stackexchange.com/questions/393349/difference-between-subshells-and-process-substitution)

command substation process substation sub shell bu kavramları netleştir

[http://mywiki.wooledge.org/ProcessSubstitution](http://mywiki.wooledge.org/ProcessSubstitution)

## Alt Kabuklar(Subshell) Hakkında

Alt kabuk yani subshell yaklaşımının çıkış noktası mevcut kabuğun birebir kopyası olan bir alt işlem oluşturup komutları bu alt kabukta yürütebilme ihtiyacıdır. Bu sayede mevcut kabuk ortamının tüm özellikleri kullanılabilirken, komutların sonuçları ana kabuğu etkileyemez çünkü alt işlemde çalıştırılmışlardır. Yani örneğin ana kabukta tanımlanmış olan değişkenler, fonksiyonlar, mevcut dizinin bilgisi, dosya tanımlayıcıları ve diğer kabuk ortam özelliklerinin tamamı alt kabuk tarafından aynen kullanılabilir. Ancak alt kabukta yapılan bir değişiklik örneğin bir değişken eklemesi veya düzenlemesi üst kabuk olan ana kabuğu etkileyemez. Bu kabuk çalıştırdığı işlemler bittiğinde sonlandırılır ve tüm değişiklikler de kaybolmuş olur. Biliyorum şu an pek anlaşılır olmadı. Daha net anlamak için bizzat uygulamalı olarak ele almaya çalışalım.

Şimdi alt işlem ile alt kabuk arasındaki farklı anlamak için basit bir test yapalım. Mevcut kabuk alt kabuğa kopyalandığı için mevcut kabukta tanımlı olan değişkenlerin alt kabukta da bulunuyor olması gerekiyor. Eğer çalıştırılan alt işlem alt kabuk değilse bu değişken değerine ulaşamayız. Bu durumu teyit etmek için ben teyit="ben degiskenim" şeklinde yazıyorum. echo $teyit komutu ile değişkenin mevcut kabukta tanımlı olduğunu görebiliyoruz. Şimdi konsola bash komutunu girerek testimizi gerçekleştirmeye başlayalım.

Mevcut kabuğa `bash` komutunu girdiğimizde, mevcut kabuğumuz sistem üzerinde bash programını arıyor ve muhtemelen /usr/bin/bash dizininde bulduktan sonra harici bir program olduğu için çocuk işlem yani alt işlem oluşturup kabuğu burada çalıştırıyor.  

bash fork exec bash

Her ne kadar yeni kabuk mevcut kabuğun altında çocuk işlem olarak çalıştırılmış olsa da bu kabuk alt kabuk değildir. Bash kabuğuna göre, çalıştırılan bu yeni kabuk yalnızca çocuk işlem olarak çalıştırılan harici bir programdır. Bu durumu teyit etmek için tekrar echo $teyit komutunu kullanabiliriz. Bakın değişken değeri bastırılmadı çünkü bu değişken bu yeni başlatılan kabuk işleminde tanımlı değil. Biz bash komutunu girdiğimizde mevcut işlem çatallandı ve exec ile tekrar bash programının talimatları bu yeni alt işleme tanımlandı. Yani yeni bir kabuk başlatılmış oldu. Bu sebeple değişken değerine ulaşamadık. Şimdi exit komutu ile bu kabuktan çıkalım. Tamamdır, ana kabuğa tekrar döndük. Hatta teyit etmek için tekrar echo $teyit komutunu girebiliriz. Bakın değişken değeri bastırıldı yani ana kabuğa dönmüş olduk. 

Şimdi ben alt kabuk oluşturmak istiyorum. Esasen alt işlem oluşturmak için birden fazla yöntem var ancak onlardan daha sonra bahsedeceğim. Alt kabuk oluşturmak için en kolay yol komutu parantez içinde yazmaktır. Bu sayede parantez içindeki komut mevcut kabuğun kopyası olan alt kabuk oluşturup bu kabuk üzerinde çalıştırılıyor. Ben denemek için (echo $teyit) şeklinde komutumu giriyorum. Bakın değişken değeri sorunsuzca bastırıldı. Alt kabukta yapılan değişikliklerin üst kabuğu etkilemediğini söylemiştik. Teyit etmek için alt kabukta yeni bir değişken tanımlayıp üst kabukta bu değişkeni sorgulamayı deneyebiliriz. Bunun için ben parantez içinde yeni-teyit="ben alt kabuğum" şeklinde yeni değişken tanımlıyorum. Komutumu onayladığımda alt kabukta bu değişken tanımlandı ve bu alt kabuğun işi bittiği için sonlandırıldı. Eğer alt kabuk üst kabuğu etkiliyorsa alt kabukta tanımlamış olduğum değişkene ulaşabiliyor olmam gerekiyor. Hemen echo $yen-teyit komutu ile teyit edelim. Bakın herhangi bir çıktı alamadık çünkü alt kabuk üst kabuğu etkilemiyor. Alt kabuk yalnızca üst kabuğun birebir kopyası olan kabuktur. Bu sayede ana kabuğu etkilemeden komutları alt kabukta sorunsuzca çalıştırabiliyoruz. 

İşte alt kabuk ve alt işlem arasındaki farklılık tam olarak budur. Eğer henüz tam olarak netleşmediyse merak etmeyin. Anlatımın devamında alt kabuk oluşturabileceğimiz farklı metotları örnekler üzerinden ele aldığımızda çok daha iyi anlayacaksınız. Alt kabuk oluşturma alternatiflerine değinmeden önce mantıksal operatörlerden de bahsdelim.

# Mantıksal Operatörler & || && ;

Bash kabuğunun özellikle programlama yapılırken kullanılan pek çok operatörü bulunuyor. Operatörden kastım özel işlevleri olan yani kabuk için özel anlama sahip olan çeşitli karakterlerdir. İşte mantıksal operatörler de bu özel karakterlere dahildir. Mantıksal operatörler kullanarak birden fazla işlemin mantıksal durumlara göre çalıştırılmasını sağlayabiliriz. Örneğin ilk işlem başarılı olursa ikinci işlemi çalıştır ya da ilk işlem başarısız olursa ikinci işlemi çalıştır gibi birden fazla işlemi mantıksal bir komut dizgisinde tanımlayabiliriz. Öncelikle yada operatörü ile başlayabiliriz.

### Ya da(veya) Operatörü ( || )

Ya da operatörü yani çift pipe "**||**" operatörü kullanıldığında, ilk komut başarısız olursa ikinci komut çalıştırılır. Eğer ilk komut başarılı olursa ikinci komut çalıştırılmaz.

Hemen uygulamalı olarak deneyelim. Ben denemek için öncelikle echo bir || echo iki şeklinde yazıyorum. Bakın ilk komut başarılı olduğu için ikinci komut çalıştırılmadı dolayısıyla iki çıktısını konsolda göremiyoruz. Eğer ilk komut hatalı olsaydı ikinci komut çalıştırılacaktı. Deneyelim. Ben denemek için ilk komut olarak asdf yazıyorum ve ya da operatöründen sonra echo iki yazıyorum. Bakın bu ilk komut hatalı olduğu için ilk komuttan sonra bu kez ikinci komut da çalıştırıldı. İşte "ya da" operatörünü kullandığımızda başarılı komut bulunana kadar sırasıyla komutlar çalıştırılıyor. Bir komut başarılı sonuç döndürürse ondan sonrası çalıştırılmıyor. Emin olmak için asdf || xyzt || echo bir || echo iki şeklinde komut girebiliriz. Bakın ilk iki komut yani ilk iki işlem başarısız olduğu için üçüncü komuta geçildi ve echo bir komutu çalıştırıldı. Ancak bu üçüncü komut başarılı olduğu için son komut çalıştırılmadı. Ya da seçeneğini ilk komutun başarısız olması durumunda çalıştırılacak ikinci bir komutunuz olduğunda kullanabilirsiniz. Bu komut olmadı, bunu çalıştır şeklinde kullanabilirsiniz. Ya da operatörü dışında diğer mantıksal operatörümüz ise ve operatörü. 

### Ve Operatörü ( && )

Ve "**&&**" operatöründe ise ya da operatörünün tersi şekilde yani sırasıyla tüm komutlar, hatalı komut ile karşılaşıncaya kadar çalıştırılır. Diğer bir deyişle, **&&** operatörü kullanıldığında soldaki komut başarılı olursa sağdaki komut çalıştırılır. Ben denemek için echo bir && echo iki && asdf && echo üç şeklinde yazıyorum ve komutu onaylıyorum. Bakın ilk komut başarılı olduğu için ikinci komut çalıştırıldı ve ikinci komut başarılı olduğu için de üçüncü komut çalıştırıldı. Ancak üçüncü komut başarısız olduğu için son komut çalıştırılmadı.  Bu mantık operatörünü peşi sıra kullandığınız komutlardan bir komutun hata vermesi durumunda devam edilmesini istemediğiniz durumlarda kullanabilirsiniz. Örneğin güncelleme işlemi için bu sudo apt update && sudo apt upgrade komutunu kullanabiliriz. Bu sayede ilk komut yani repo indexlerini güncelleme işlemi başarılı ise yükseltme işlemi uygulanır. Eğer index bilgileri güncellenmezse zaten paketleri yükseltme işlemi de başarısız olacağı için ilk komut başarılı olmadan ikinci komutun çalışmasının bir önemi yoktur. İşte sizler de tıpkı bu basit örnekte olduğu gibi çalıştırılması için kendisinden önceki komutların başarılı olmasına ihtiyaç duyan komutlarınız için "ve" operatörünü kullanabilirsiniz. Ayrıca söz konusu peşi sıra birden fazla komutu çalıştırmak olduğunda koşullu mantıksal operatörler dışında noktalı virgül ile kullandığımız komut ayırıcı olarak geçen noktalı virgül karakteri de bulunuyor. Hazır birden fazla komutu çalıştırmayı ele almışken bu karakterden de bahsedelim.

### Komut Ayırıcı ( ; )

Noktalı virgül bash kabuğu üzerinde önceki ya da sonraki komutun çıkış durumundan yani hatalı ya da hatasız olmasından bağımsız olarak, komutların hepsini peş peşe çalıştırmamızı sağlayan karakterdir. Komutlar arasında noktalı virgül kullandığımız sürece peşi sıra istediğimiz sayıda komut girip hepsinin soldan sağa doğru sırasıyla çalıştırılmasını sağlayabiliriz. Ben denemek için echo bir ; asdf; echo iki ; xyzt ; echo üç şeklinde komutumu giriyorum. Bakın hatalı da olsa hatasız da olsa tüm komutlar yazıldığı gibi yani soldan sağa doğru sırasıyla çalıştırıldı. 

Ayrıca ben hep ayrı ayrı bahsettim ancak mantıksal operatörler ile komut ayırma karakteri de bir arada kullanıp özel koşul belirten komut dizesi de hazırlayabilirsiniz. Örneğim ben yalanızca ilk komut yanlışsa geri kalan tüm komutların çalıştırılması için ilk komutun ardından ya da operatörünü kullanabilirim. Bir önceki komutun başına asdf ekliyorum ve || operatörünü kullanıyorum. Bakın ilk komut hatalı olduğu için geri kalan tüm komutlar sırasıyla çalıştırıldı. İlk komutu echo test komutu ile değiştirelim yani ilk komutu başarılı olacak şekilde değiştirelim ve komutu onaylayalım. Bakın şimdi de yalnızca ilk komut başarılı olduğu için veya operatörünün yapısı gereği ikinci komut başarılı da olsa geçilmedi ama ondan sonrakiler noktalı virgül sayesinde yine sırasıyla bastırıldı. Peki ama neden böyle oldu ? Aslında bunun sebebi tüm komutun parça parça işleniyor olması. Yani kabuk ilk olarak buradaki ilk koşula baktı ve ilk komut doğru olduğu için veya operatörü sebebiyle ikinci komutu çalıştırmadı. Ama bu ikinci komuttan sonra başka bir veya operatörü olmadığı için de diğer komutları sırasıyla çalıştırdı. Eğer buradaki komutların hepsini tek bir koşula bağlı kılmak isteseydik yani örneğin ilk komut başarısız olursa diğerlerini çalıştır eğer ilk komut başarılı ise diğer hiç bir komutu çalıştırma demek isteseydik komut gruplama özelliğini kullanabilirdik. Hadi komutları nasıl gruplayabileceğimizden bahsederek devam edelim. Zaten komut gruplama yapısı alt kabuk oluşturularak kullanıldığı için hazır yeri gelmişken nasıl alt kabuk oluşturulduğuna dair örnek de vermiş oluruz. 

# Komut Gruplama

[https://www.gnu.org/software/bash/manual/html_node/Command-Grouping.html](https://www.gnu.org/software/bash/manual/html_node/Command-Grouping.html)

Eğer daha önce kabuk programlama ile ilgilendiyseniz komut gruplama kavramını mutlaka duymuşsunuzdur. Komut gruplama birden fazla komutu tek bir grup içinde alarak tek bir işlem gibi ele almamız mümkün kıldığı için özellikle kabuk programlamada çok işlevsel olabiliyor. Örneğin komut gruplama sayesinde tüm komutların çıktılarını kolayca tek bir adrese yönlendirebilir ya da tek seferde tüm komutların arkaplanda çalışmasını da sağlayabiliriz ya da komutları mantıksal operatörleri de kullanarak çeşitli koşullara bağlayabiliriz. Kısacası komut gruplama sayesinde birden fazla komutu tek bir komut gibi ele alıp yönetmemiz mümkün oluyor. Çünkü gruplanmış komutlar tek bir işlem gibi davranıyor. Biliyorum şu an söylediklerimden pek bir şey anlamadınız, o yüzden hemen örneklere geçelim.

Komut gruplama için bash kabuğunda standart ve kıvırcık parantez kullanımı olmak üzere iki farklı alternatif yöntem bulunuyor. Standart parantez gruplaması ile başlayacak olursak;

Standart parantezde tüm komutlar yeni bir altkabuk oluşturup bu kabukta çalıştırıyor. Dolayısıyla ana kabuğun kopyalanmış ortamında çalışmasına karşın bu komutların sebep olduğu değişiklikler ana kabuğu etkilemiyor.

Ben öncelikle daha önce bahsetmiş olduğum koşul durumunu oluşturmak istiyorum. Yani peşi sıra birden fazla komut gireceğim ama bu komutlar yalnızca ilk komut başarısız olursa çalıştırılacak. Bunun için öncelikle asdf || şeklinde yazıp hatalı komutu ve "ya da" mantıksal operatörünü ekliyorum. Şimdi diğer komutların bu ilk koşula bağlı olabilmesi için parantez açmamız gerekiyor. Bu parantezin için de echo bir ; xyzt; 1234; echo iki şeklinde yazıp parantezi kapatıyorum. Şimdi komutu onaylayıp sonucunu değerlendirelim.

Bakın ilk komut başarısız olduğu için doğrudan ikinci komuta yani aslında komut grubuna geçildi. Bu grup içinde noktalı virgül kullandığı için de komutların hatalı veya hatasız olmasına bakılmaksızın tüm komutlar sırasıyla çalıştırıldı.

Şimdi aynı örneği bu kez ilk komutu başarılı olacak şekilde değiştirip girelim. Ben örnek olarak ilk komutu echo test şeklinde değiştiriyorum. Bakın bu kez ilk komut haricinde hiç bir komut çalıştırılmadı çünkü ya da operatörü dolayısıyla ilk komut başarılı olduğunda ikinci komutu yani komut grubunu çalıştırmaya geçilmedi.

Aynı örneği ve operatörü için de uygulayabiliriz. Hatta peş peşe operatörleri ve komut gruplarını da kullanabiliriz. Ancak neticede işleyişi kavradığımızı düşünüyorum. Eğer kavrayamadıysanız kendi kendinize çeşitli örnekler yapabilirsiniz. Ayrıca ben standart parantez içindeki komutların alt kabuk oluşturulup burada çalıştırıldığını söyledim ama doğrudan bu durumu teyit etmedik. Ben teyit etmek için yine mevcut kabuğumda teyit="yeni değer" şeklinde yeni bir değişken tanımlıyorum. echo $teyit komutu ile de değişkenin tanımlı olduğunu görebiliyoruz. Şimdi parantez içinde bu değişkeni çağırmayı deneyelim. Ben örnek olarak (echo bir ; echo $teyit) şeklinde komutumu giriyorum. Bakın ilk komut ve ardından ana kabukta tanımlamış olduğum teyit değişkeninin değeri konsola bastırıldı. Yani bu komut gruplama yapısının aslında alt kabuk üzerinde çalıştığını teyit ettik. Hatta subshell olduğuna hala emin olamadıysanız bash kabuğunun subshell derinliğini sayan BASH_SUBSHELL değişkenini de kullanabilirsiniz. Bakın mevcut kabukta echo $BASH_SUBSHELL komutu ile alt kabuk derinliğini sorguladığımzda 0 çıktısını aldık. Şimdi (echo $BASH_SUBSHELL) komutunu girelim. Bakın bu kez çıktı 1 oldu. Buradaki 1 rakamının anlamını bu değişkenin çağırıldığı kabuğun bir üstünde kabuk olduğudur. Hatta istersek bu komut gurubu içinde (echo $BASH_SUBSHELL; (echo $BASH_SUBSHELL)) komutu ile bir grup daha yani bir alt kabuk daha açıp yine aynı değişkenin değerini sorgulayabiliriz. Bakın ilk çıktı 1 rakamı iken ikinci çıktı 2 rakamı oldu. Çünkü ilk değişken sorgulama bir alt kabukta yapılmışken ikinci sorgulama alt kabuğunda altında olduğu için 2. alt kabuk olarak çıktı aldık. Alt kabuk sayesinde ana kabuğun birebir kopyasının alt işlemde sorunsuzca kullanılabildiğiniz ve alt kabuktaki hiç bir değişikliğin üst kabuğu etkilemediğini biliyoruz. Bu doğrultuda komutlarını kullanabilirsiniz.

Komut gruplarken standart parantez haricinde bir de kıvırcık parantez kullanımı var.

Kıvırcık parantezin standart parantez gruplamasından farkı, kıvırcık parantezin yeni bir alt kabuk oluşturmadan komutları mevcut kabuk ortamı üzerinde çalıştırıyor olmasıdır. Yani yeni bir altkabuk veya alt işlem oluşturulmuyor. Bu sebeple bu gruptaki komutların uyguladığı değişiklikler ana kabuğu da doğrudan etkiliyor. Bu sebeple komut gruplama için kıvırcık parantez kullanırken dikkat etmek gerekiyor.

Ayrıca davranışı dışında kıvırcık parantez kullanımı yani yazılışı konusunda da dikkat etmek gerekiyor. Yazılışı { komut1; komut2; } şeklinde olmalı. Yani komutları girerken kıvırcık parantezden sonra bir boşluk karakteri bırakıp daha sonra komutları girmemiz gerekiyor. Aksi halde kabuk kıvıcık parantezin komut gruplama görevini doğru şekilde algılayamıyor. Ve ayrıca komutların sonunda yine noktalı virgül kullanmamız gerekiyor çünkü bu komut gurubu mevcut kabuğun yerini aldığı için bu komutlardan sonra çalıştırılacak işlem olarak tekrar bash kabuğunun kullanılabilir olması gerekiyor. Hemen örnek üzerinden görelim. Daha önce "ya da" koşul durumunu kullanmıştık şimdi de ve koşulu ile kullanalım. Ben örnek olarak echo test && { echo 1 ; asdf ; echo 2;} şeklinde yazıyorum. Bakın ilk komut başarılı olduğu için ikinci komut yani komut grubu çalıştırıldı. İlk komutu xyzt olarak değiştirip komutumuzu tekrar girelim. Bakın bu kez ilk komut yanlış olduğu için "ve" operatörü ikinci komutu çalıştıramadı. "ve" operatörünün davranışını zaten biliyoruz. Burada asıl dikkat etmemiz gereken kıvırcık parantez kullanım davranışıdır. İlk komutu tekrar başarılı çalışacak şekilde değiştirelim örneğin echo test yapalım. Şimdi kıvırcık parantez kullanımı için söylediğim yazım kurallarının geçerli olup olmadığını teyit edebiliriz. Örneğin ilk komut ile kıvırcık parantez arasındaki boşluğu silip komutu tekrar girmeyi deneyebiliriz. Bakın syntax yani söz dizim hatası verdi. Yani boşluk bırakmak önemli görebildiğiniz gibi. Bunun dışında önce boşluk sorununu düzelttikten sonra, parantezi kapatmadan önce noktalı virgül kullanmadığımızda ne olacağını da görmek için noktalı virgülü silelim ve komutu tekrar girelim. Bakın konsol bir alt satıra geçti ve hala bizden komut bekliyor. Komut bekliyor çünkü kıvırcık parantez kullandığımızda buradaki komutlar mevcut kabuk üzerine çalıştırıyor dolayısıyla son komuttan sonra noktalı virgül koymadığımızda kabuk bu komutu tamamlayıp yeni komutlar girebilecek hale gelemiyor. 

Bu durum da aslında kıvırcık parantezin mevcut kabuk üzerinde çalıştığının bir kanıtı. Hatta isterseniz daha önce tanımlamış olduğumuz teyit değişkenini kıvırcık parantez içinden bastırmayı deneyelim. Bakın değişken değeri sorunsuzca bastırıldı. Ama bu doğrudan alt kabuk oluşturulmadığını yani kıvırcık parantezin mevcut kabuk ortamını kullandığını kanıtlamıyor çünkü alt kabuklarda da ana kabuğun değişkenlerine ulaşabiliyoruz. Ben kıvırcık parantezin komutları çalıştırmak için doğrudan ana kabuğu kullandığını kanıtlamak için kıvırcık parantez içinde yeni bir değişken tanımlamak ve daha sonra ana kabuk üzerinde bu değişkenin değerini bastırmayı denemek istiyorum. Ayrıca daha önce standart parantezde kullandığımız BASH_SUBSHELL değişkenini bastırarak alt kabuğun kullanılıp kullanılmadığını da öğrenebiliriz. Ben öncelikle yeni bir değişken tanımlamak için {yeni="yeni değişken"; şeklinde yazıyorum ve daha sonra kıvırcık parantez içindeki komutların hangi alt kabuk derecesinde çalıştırıldığını öğrenmek için echo $BASH_SUBSHELL; komutunu da ekliyorum ve parantezi kapatıyorum. Bakın aldığım çıktı 0 oldu çünkü kıvırcık parantez alt kabukta değil doğrudan ana kabukta çalıştırılıyor. Emin olmak için şimdi mevcut kabuğa yani ana kabuğa echo $yeni komutunu girelim. Bakın yeni değişken ifadesi konsola bastırıldı. Bu çıktı da kıvırcık parantez içindeki komutların ana kabuğu kabukta çalıştırıldığının ve dolayısı ile kıvırcık parantez içindeki komutların ana kabuğu etkileyebileceğini kanıtlıyor. 

Bu bağlamda kıvırcık parantez ile komutları gruplarken çalıştırılacak komutların mevcut kabuk üzerindeki etkilerini unutmayın lütfen. Eğer mevcut kabuğun etkilenmesini istemiyorsanız standart parantez içinde komutları gruplayabileceğinizi de zaten biliyorsunuz.

Biliyorum bu anlatımlar temel sistem yönetimi için biraz detaylı gibi ancak ileride kabuk programlamayı öğrenmek isteyen ya da karşılaştığında bu komutların anlamlarını bilmek isteyenler için tüm bu kavramlardan da bahsetmek istiyorum.

Gelin şimdi alt kabuk oluşturan bir diğer yapıdan yani komut ikamesinden bahsederek devam edelim. Zaten kabuk genişletmelerinde görmüştük şimdi tekrar alt kabuk özelinde ele alalım.

## Komut İkamesi (Command Substitution)

Kabuk genişletmelerinden bahsederken komut ikamesinden de bahsetmiştik hatırlıyorsanız. 

Tekrar hatırlayacak olursak ikame kelimesi "yerine koyma, yer değiştirme" anlamına geliyor. Komut ikamesi sayesinde, bir komutun çıktılarını tekrar kabuğa komut girdisi olarak verilebiliyor. Bu işlem de aslında ilgili komutun alt kabuk üzerinde çalıştırılıp sonuçlarını tekrar üst kabuğa girdi olarak iletmesiyle mümkün oluyor. Hemen bizzat uygulamalı olarak görelim. Örneğin ben konsola echo ls yazarsam görebildiğiniz gibi yalnızca ls ifadesini çıktı olarak alıyorum. Eğer bu ls ifadesini komut ikamesi içinde yazarsam yani ters tırnak içinde veya dolar işaretinden sonra açtığım parantez içine yazarsam bu ls komutu alt kabukta çalıştırılacak ve çıktılar echo komutuna argüman olarak verilecek. Hemen komutu onaylayalım. Bakın bu kez ls komutu alt kabukta çalıştı ve mevcut dizin içeriğini çıktı olarak komut ikamesinin yerine koydu, echo komutu da bu çıktıları konsola standart şekilde bastırdı. Eğer burada echo ifadesini kullanmazsak ls komutunun çıktıları tekrar bash kabuğuna yönlendirileceği için komut ikamesinin çıktıları tekrar kabuğa komut olarak girilmiş olacaktı. Hemen denemek için echo ifadesi olmadan komutumuzu tekrar girelim. 

Bakın bu kez tüm dosya ve dizin isimleri birer komutmuşçasına bash kabuğuna yönlendirildi. Biz yalnızca ilk dosya veya dizinin adını gördük çünkü isimler arasında boşluk olduğu için kabuk ilk komutta hata alınca diğerlerine bakmıyor. Denemek için konsola 1 2 3 şeklinde yazabiliriz. Bakın yine yalnızca 1 komutu bulunamadı şeklinde hata alıyoruz. Neticede komut ikamesinin davranışını bir kez daha hatırlamış olduk. Şimdi komut ikamesindeki komutların alt kabukta çalıştığını teyit etmek için BASH_SUBSHELL değişkenini kullanabiliriz. Ben denemek için echo $(echo $BASH_SUBSHELL) şeklinde komutumu giriyorum. Bakın çıktı olarak 1 değerini aldık çünkü komut ikamesi de bir alt kabukta çalışıyor. Dilerseniz ana kabukta tanımlı bir değişkeni bu komut ikamesi içinden çağırmayı da deneyebilirsiniz. Neticede komut ikamesi içindeki komutların alt kabukta çalıştırılıp, çıktılarının üst kabuğa girdi olarak aktarıldığını öğrenmiş olduk.

Komut ikamesine doğrudan gündelik kabuk kullanımında nadiren ihtiyacınız olsa da bash kabuk programlama yaparken komut ikamesi işlerinizi kolaylaştırabilir. Örneğin bir komutun çıktılarını bir değişkene atamak isterseniz değişken=komut ikamesi içinde çalıştırılacak komut şeklinde girebilirsiniz. Ben örnek olarak ls komutunun çıktısını liste isimli bir değişkene atamak istiyorum. Bunun için liste=$(ls) şeklinde komutumu giriyorum. Şimdi echo $liste komutu ile değişkenin değerini bastıralım. Bakın ls komutunun çıktıları liste değişkenin değeri olarak tanımlanmış. Komut ikamesinin özellikle kabuk programlamada bu ve bunun gibi pek çok farklı durumda işlerimizi kolaylaştıran bir yapı.

# Pipe

ÖNCE PİPE OLUŞTURULUYOR DAHA SONRA İLK VE İKİNCİ ALT İŞLEM OLUŞTURULUYOR

Pipe kullanımından daha önce de bahsetmiştik. Şimdi alt kabuk özelinde tekrar kısaca ele alalım. Pipe kullanıldığında pipe ile ayrılmış olan komutlar ayrı ayrı alt kabuk başlatılarak bu kabuklar üzerinde yürütülürler. Örneğin ben konsola ls | sort -r şeklinde komut girdiğimde iki yeni alt kabuk çatallanıyor ve iki komut ayrı ayrı bu alt kabuklarda çalıştırılıyor. ls komutunun çıktıları doğrudan sort komutunun girdisi olarak iletiliyor. Pipe mekanizmasının alt kabuk kullanması sayesinde mevcut kabuk üzerinde tek tek komut girip gerçekleştirebileceğimiz çok aşamalı görevleri pipe üzerinden birbirine bağlı şekilde yerine getirebiliyoruz. Aslında pipe kullanımını daha önce de görmüştük. Şimdi basit bir örnek üzerinden tekrar ele alalım. Örneğin ben ls -R /etc komutunu girdiğimde özyinelemeli olarak /etc dizini altındaki tüm alt dizinler ve içerikleri konsola bastırılıyor. Eğer bu dizinler içinde istediğim ifade ile eşleşen bir dosya veya klasör var mı diye merak edersem bunu grep aracı ile filtreleyerek öğrenebilirim. Hatta eşleşen ifadelerin sort komutu ile alfabetik olarak sıralanmasını da sağlayabilirim. Bu örnek için Pipe kullanmayacaksak ls komutunun çıktılarını yönlendirme operatörü ile bir dosyaya kaydedip daha sonra bu dosya içeriğinin grep aracı tarafından okunup filtreleme yapmasını sağlayabiliriz. Ve bu filtrelenen çıktıları da yine bir dosyaya yönlendirip bu dosyayı da sort komutu ile alfabetik olarak sıralayabiliriz. Ancak pipe dururken dosyaları kullanmak yani bu verimsiz işlemleri uygulamak anlamsız. Çünkü herhangi bir dosya oluşturmadan doğrudan ilk komutun çıktılarını bir sonraki komuta pipe ile aktarabiliriz. 

Yani örneğin ben komutumu ls -R /etc | grep test | sort şeklinde girdiğimde, bakın etc dizini altında test ifadesinin geçtiği içerikler alfabetik olarak listeleniyor. Buradaki komutun nasıl çalıştırdığında kısaca değinecek olursak: Öncelikle mevcut kabuğun kopyası olan üç alt kabuk çatallanıyor. Daha sonra bu kabuklar üzerinde ilgili komutlar aynı anda paralel olarak çalıştırılıyor. İlk komutun stdout yani çıktısı ikinici komutun stding yani girdisi olarak bağlanıyor. İkinci komutun çıktısı da üçüncü komutun girdisi olarak bağlanıyor. Son komutun çıktısı da aksi belirtilmedikçe konsola yönlendirilmiş oluyor. Böylelikle araçlar paralele olarak çalıştırıldığı için önceki aracın çıktıları anında bir sonraki araca yönlendirilip işlenebiliyor. Elbette veri aktarımında önceki araçtan gelen verileri pipe üzerinden okuyabilecek ve çalışma hızı bakımından uyumlu araçlar kullanılmalı. 

Bu yapı sayesinde birden fazla aracı birbirine bağlayarak spesifik olarak istediğimiz çözümü sunan bir işlem hattı oluşturabiliyoruz. Yani basit yapıdaki birden fazla aracı birbirine bağlayıp uyguladığımız kombinasyon ile tek bir araçta bulunmayan çok spesifik çözümlere ulaşmış oluyor. Zaten unix felsefesi gereği araçların genellikle basit olması ama işini iyi yapması, bu işini iyi yapan basit araçların da bir araya getirilerek durumlara özel spesifik çözümler sunulabilmesi yaklaşımı vardır.

Zaten daha önce de pipe kullanımını ele aldığımız için şimdi tekrar birden fazla örneğe değinmemize gerek yok. Bu noktada öğrendiğimiz ek detay pipe üzerindeki komutların birer alt kabuk üzerinde paralel olarak çalıştıklarıdır. Ayrıca pek sık ihtiyaç duyulmasa da anlatımın devamını kavrayabilmek için kısaca adlandırılmış pipe lardan bahsetmek istiyorum.

# Named Pipe | Adlandırılmış Pipe

İngilizce named pipe olarak geçen Türkçe'ye de adlandırılmış veya isimlendirilmiş pipe olarak çevirebileceğimiz işlevsel bir mekanizma bulunuyor. Daha önce iki işlemi birbirine bağlarken kullandığımız pipe işareti anonymous pipe ya da regular pipe yani anonim veya sıradan pipe olarak geçiyor. Peki tüm bu isimlendirmeler ne anlama geliyor ? Hemen açıklayalım.

Biz standart pipe işareti ile iki işlemi birbirine bağlarken bu pipe sayesinde ilk işlemin çıktıları ikinci işleme aktarılabiliyordu. Yani işlemler arası iletişim için pipe işaretini kullanabiliyoruz. Bu harika ancak bu pipe işareti yalnızca iki işlem arasındaki tek yönlü ve tek seferlik iletişimi sağlıyor. Biz birden fazla aracın girdi yapabileceği ve ayrıca girdi alabileceği bir pipe mekanizması istersek isimlendirilmiş pipe mekanizması kullanabiliriz. 

İsimli pipe dosya sistemi üzerinde tıpkı dosya gibi görünen ancak diskte hiç veri barındırmayan bir adreslemeye yöntemidir. Bu dosyaya yönlendirilen veriler yine bu dosya üzerinden veri girdisi bekleyen araçlara ulaştırılır. Yani aslında tıpkı standart pipe gibidir ancak ismi olduğu içinde bu ismi kullanarak birden fazla araç bu veri kanalına veri gönderebilir veya aynı şekilde birden fazla araç bu veri kanalındaki verileri okuyabilir. Tüm veriler giriliş sırasına göre kanaldan aktarılır. Veri aktarımının sıralı yapıldığına işaret eden ilk giren ilk çıkar ifadesinin ingilizce karşılığı *First In First Out*'dur. Bu ifadenin kısaltması olarak da FIFO kullanılır. 

Daha net anlamak adına öncelikle yeni bir isimli pipe oluşturalım. Bunun için mkfifo komutunu kullanabiliyoruz. Buradaki fifo ifadesini biraz önce açıkladığımız için mkfifo komutu akılda kalıcıdır.

Ben mkfifo kanal komutu ile kanal isminde bir isimli pipe oluşturuyorum. Şimdi ls -l komutu ile listeleyelim. Bakın oluşturduğum isimli pipe dosyasının başında p ifadesi bulunuyor. Pipe dosyaları bu şekilde ifade edildiği için bu çıktıyı aldık. Ayrıca görebildiğiniz gibi dosyanın boyutu sıfır. Üzerinden veri aktardıktan sonra da aynen bu şekilde 0 olacak. Hemen denemek için veri aktarma örneği yapabiliriz. Basit ama kolay gözlemlenebilir bir örnek olması için ben iki farklı konsoldan veri girişi yapıp iki farklı konsoldan da bu verileri almak istiyorum. Bunun için öncelikle 4 adet konsolun açılmasını sağlayalım.

Konsola açtıktan sonra ben iki konsola cat >> kanal komutunu giriyorum. Bu komut sayesinde bu konsollara girdiğimiz ifadeler kanal isimli dosyaya yani aslında isimli pipe aktarılacak.

Şimdi diğer iki konsoldan isimli pipe yani kanal dosyasını okumak üzere cat < kanal komutunu girelim.

Tamamdır. Şimdi iki konsoldan ne girersek girelim doğrudan kanala yönlendirilecek oradan da bu sırasıyla bu dosyayı okumaya başlamış olan işlemlere yönlendirilecek. Denemek için benden girdi bekleyen konsolun ilkine test yazıp onaylıyorum. Bakın anında diğer konsola iletildi. İletim sırasıyla yapıldığı için ben konsola emir girdiğimde yalnızca kanal dosyasını ilk okumaya başlayan işleme iletildi. Tekrar test ifadesini yazıp onaylıyorum. Bakın bu kez kanal dosyasından veri bekleyen ikinci konsola ulaşmış oldu. Tüm veriler sırasıyla iletildiği için bu durum yaşanıyor. Aynı pipe dosyasına birden fazla işlemin veri gönderebildiğini görmek adına ikinci konsola da test2 yazıp onaylıyorum. Bakın bu konsol üzerinden de veri iletebildim. Tekrar yazdığımda ikinci konsola da ulaştığınız görebiliyoruz. İşte bizzat test ettiğimiz üzere isimli pipe dosyasına aynı anda birden fazla işlem veri gönderebiliyorken, veriler sırasıyla alıcısına ulaştırılıyor. Belki bu ele aldığımız örnek pek kullanışlı olmayabilir ancak sonuçları bizzat görmek adına bence açık bir örnek olduğu için ele almak istedim. 

İsimli pipe kullanımın avantajı diskte veri depolamadan birden fazla işlemden gelen verileri sırasıyla iletebilmesidir. Bu durum hem verimlilik hem de esneklik açısından faydalı oluyor. Diskte veri depolanmadığını ls -l kanal komutu ile de teyit edebiliriz. Bakın dosyanın diskte kapladığı alan 0 yani üzerinden veri geçerken veya geçtikten sonra diskte veri tutulmadığını da bizzat teyit ettik.

Gerçek hayattan örnekleyecek olursak standart pipe kullanımını sabit tesisat borusu olarak düşünebilirken isimli pipe yapısını hareket edebilen çoklu bahçe hortumu gibi düşünebiliriz. Sabit tesisat olduğu yerdeki aktarım işini yaparken, hortumu istediğimiz serbestlikte kullanabiliriz. 

![]({{ site.url}}/egitimserisi/img/18-%20I%CC%87s%CC%A7le%2075bff/Untitled%204.png)

Neticede standart pipe işaretini kolayca çağırıp kullanabilme imkanımız olmadığı için bir isim üzerinden pipe kanalını kullanabiliyor olmak gerektiğine işimize yarayabilecek bir avantajdır. Buradaki dosyanın gerçekten veri barındırmayan sanal bir dosya olduğunu yani yalnızca aktarım yapılabilmesi için kullanılan işaretçi olduğunu zaten biliyoruz. Yani biz isimli pipe kullanarak, ben bu veriyi x dosyasına aktarıyorum okumak isteyen x dosyasına baksın demiş oluyoruz. Hatta eğer isimli pipe a gönderilen verileri okumak için bekleyen hiç bir işlem yoksa bu veriler aktarılmaz. Çünkü veriler sabit değildir akış halindedir alıcısı yoksa, verilerin boşa akıtılması anlamsızdır. Örneğin ben denemek için find komutunu kullanarak s ifadesi ile başlayan her şeyi araştırmak istiyorum. Bu işlemin çalışıp çalışmadığını takip edebilmek için de top aracını kullanmak istiyorum. Top aracı aktif olarak çalışmakta olan işlemlerin kullandıkları sistem kaynaklarıyle birlikte bir listesini sunduğu için find işlemi çalışırken bu listede görebileceğiz. Ben öncelikle yeni bir konsol açıp bu konsola top komutunu yazıyorum. Bakın aktif işlemler burada listeleniyor. Şimdi bir de diğer konsola sudo find / -name s* komutunu girelim. Bakın komutumu onayladıktan hemen sonra burada sistem kaynak kullanımında en üst sırada find aracının olduğu görülebiliyor. Ve find aracı da eşleşen tüm ifadeleri konsola bastırılıyor. Peki bu çıktıları isimli pipe olan kanal dosyasına yönlendirseydik ve bu dosyayı okumasaydık ne olurdu ? Hemen deneyelim. Ben komutun sonuna > kanal ifadesini ekleyip tekrar giriyorum. Bakın şu anda aktif işlem listesinde find aracının çalıştığına dair bir emare yok. Yok çünkü, bu komut çalıştırılırsa çıktıları alacak hiç kimse yok. Dolayısıyla bu komutu şu an çalıştırmanın bir anlamı yok. Bu durumdan kesin emin olmak için kanal dosyasını okumayı deneyebiliriz. Bakın find komutu hala işlem listesinde değil ve komutu girdiğimiz konsolda da çalıştığına dair herhangi bir çıktı yok. Şimdi yeni bir konsol açalım ve isimli pipe dosyasını okuyunca neler olacağını görelim. 

Bakın bir anlığına yine find komutu işlem listesinde en üste geldi ve çıktıları da kanal dosyasını okuduğumuz konsola bastırılmış oldu. Tıpkı çeşmeyi açmadan suyun gelmiyor olması gibi eğer verileri okumak isteyen bir işlem yoksa verilerin boşa akıtılmasının önlemesi için verileri üretilerek boşuna kaynak harcanmıyor. Kullanımına dair farklı örnekler de verilebilir belki ama çok sık ihtiyaç duyulmadığı için ve kafanızı karıştırmak istemediğim için temel seviyede bu kadarlık bilgi yeterli.

Neticede her şeyin bir dosya gibi ele alınması yaklaşımın sunduğu esnekliğe bir kez daha bizzat tanık olduk gördüğünüz gibi. Bu esnekliğe ihtiyaç duyduğunuzda temel olarak isimli pipe mekanizmasının da nasıl çalıştığını artık biliyorsunuz. Dosya gibi ele alındığı için, isimli pipe dosyasını silmek için rm komutunun ardından pipe dosyasının isminiz girmemiz yeterli. 

## İşlem İkamesi(Process Substitution)

İşlem ikamesi, daha önce ele aldığımız isimlendirilmiş pipe a benzer şekilde çalışıyor. Ancak doğrudan bir dosya oluşturmamız gerekmiyor. İşlem ikamesi sayesinde komutların çıktıları tıpkı bir dosya gibi ele alınabilir. Daha net anlamak adına birkaç deneme yapalım. İşlem ikamesi özelliğini kullanmak için öncelikle yönlendirme operatörünü kullanıp daha sonra parantez içinde istediğimiz komutu yazabiliriz. 

Örneğin ben echo <(ls) şeklinde yazdığımda çıktı olarak geçici bir dosya ismi bastırılmış oldu. Bu dosya ls komutunun çıktılarının okunabileceği dosyadır. Ls komutunun çıktıları geçici olarak oluşturulmuş olan bu dosyaya tıpkı daha önce ele aldığımız isimli pipe gibi yönlendirliyor. Eğer bu dosyayı okumak üzere bekleyen bir işlem varsa bu içeriği görebiliyor. echo komutunun dosyaları okumadığını daha önce pek çok kez ele aldık. Buradaki çıktıda dosya ismini almış olma nedenimiz de echo komutunun dosyayı okumak yerine doğrudan yalnızca ismini bastırmasıdır. Eğer aynı komutu echo yerine cat aracı ile tekrar girersek cat aracı dosyaları okuduğu için bu kez ls komutunun çıktılarını alıyor olacağız. Hemen deneyelim. Bakın bu kez dosya ismi yerine ls aracının çıktılarını almış olduk çünkü cat aracı geçici olarak oluşturulan bu dosyayı okumamızı sağladı.

Bu yapı sayesinde komutların çıktılarının geçici dosyalar üzerinden farklı işlemlere aktarılması mümkün oluyor. Kullanımına dair basit bir örnek vermemiz gerekirse iki farklı ls komutunun çıktılarını kıyaslamayı deneyebiliriz.

Ben örnek olarak diff <(ls -l) <(ls -la) şeklinde komutumu giriyorum. Bakın ls -l komutunun çıktıları ile ls -la komutunun çıktılarının kıyaslamasını kolayca bu yapı sayesinde gerçekleştirebildim. Normalde bu yapı olmasa her iki komutun çıktılarını da birer dosyaya kaydedip daha sonra bu dosyaları diff komutuna argüman olarak vermem gerekcekti. Ve işim bittiğinde bu dosyaları da silmem gerekcekti. Ama işlem ikamesi sayesinde aynı işi kısayoldan gerçekleştirebiliyorum. Çünkü komutların çıktılarını geçici olarak bir dosya üzerinden ulaşılabilir kılan bir yapı var. Bu yapı isimli pipe gibi çalıştığı için disk üzerinde hiç bir veri depolamıyor yani geçici olarak dosyaların kullanılmasını sağlıyor ve işi bittiğinde bu geçici dosyaları da ortadan kaldırıyor. Özetle birden fazla komutun çıktılarını tek bir komuta dosya okurmuşçasına yönlendirirken bu yapı son derece pratik. Özellikle kabuk programlamada ihtiyaç duyabileceğiniz ve başka insanların programladığı betikleri okurken sık karşılabileceğiniz bir yapıdır. Ben örnek olarak iki komutun çıktısını tek bir işleme okunacak dosyalar gibi yönlendirdim. Bunun haricinde komutun içine veriler yazmasını istediğimiz bir dosya şeklinde de komut girebiliriz. Örneğin ben ls | sort komutu ile ls komutunun çıktılarını listeleyebiliyorum. Bunun yerine istersem ls > >(sort) komutunu da kullanabilirim. Bu kullanımda ls komutunun standart çıktıları sort komutunun okuduğu geçici dosyaya girdi olarak aktarılıyor. Buradaki >(komut) kullanımında komut, işlem ikamesi sayesinde geçici olarak oluşturulan dosyayı okumayı bekliyor. Yani aslında buradaki ifade arkaplanda ls > /dev/fd/63 şeklinde ls komutunun bir dosyaya veri yönlendirmesi şeklinde ele alınıyor. sort komutu da çalıştırıldığı alt kabukta standart girdi olarak yine bu /dev/fd/63 dosyasını okuyor. Neticede ilk komutun çıktıları alt kabukta çalıştırılan ikinci komuta girdi olarak anında iletilmiş oluyor. Daha önceki <(komut) kullanımında buradaki komut çıktılarını aktarmak için burada oluşturulan geçici dosyayı kullanıyordu. Yani örneğin cat <(ls) komutu arkaplanda ls komutunun standart çıktılarını /dev/fd/63 gibi bir pipe dosyasına aktarıyor, cat komutu da girdileri bu dosyadan okuyor. Yani komutumuz cat /dev/fd/63 halini almış oluyor dolayısıyla bu geçici pipe üzerindeki veriler cat komutuna dosya girdisi olarak aktarılıp konsola bastırılımış oluyor. Borular ve giriş yönlendirmeleri, içeriği STDIN akışına iter. İşlem ikamesi komutları çalıştırır, çıktılarını özel bir geçici dosyaya kaydeder ve ardından komut yerine bu dosya adını iletir. Hangi komutu kullanırsanız kullanın, onu bir dosya adı olarak kabul eder. Oluşturulan dosyanın normal bir dosya olmadığını, ancak artık gerekmediğinde otomatik olarak kaldırılan adlandırılmış bir kanal olduğunu unutmayın.

İsimli pipe'ın doğrudan isim belirtilmeden kullanılması gibi düşünebilirsiniz. 

İşlem ikamesinin alt kabukta çalıştığını teyit etmek için basitçe cat <(echo $BASH_SUBSHELL) komutu ile alt kabuk değişkenini sorgulayabilirsiniz. Bakın 1 çıktısını aldık yani komutların işlem ikamesi sayesinde bir alt kabukta çalıştırıldığını da bizzat teyit etmiş olduk.

+

Bir alt kabukta çalışır

Komutun standart çıktısını önceki komuta aktarmak için `<(komut)` 

Bir önceki komutun standart çıktısını standart girdi olarak kullanmak için `>(komut)` yapısı kullanılır.

`
$ cat <(date)
Thu Jul 21 12:40:53 EEST 2011
`

Aslında bir STDIN akışı verilmek yerine, cat'e açılması ve okunması gereken bir dosyanın adı verildi. Bunu test etmek için cat yerine echo komutunu kullanabiliriz.

`
$ echo <(date)
/proc/self/fd/11
`

cat dosya adını aldığında, dosyanın içeriğini bizim için okudu. Öte yandan, echo bize iletildiği dosyanın adını gösterdi. Daha fazla ikame eklerseniz bu fark daha belirgin hale gelir:

`
$ cat <(date) <(date) <(date)
Thu Jul 21 12:44:45 EEST 2011
Thu Jul 21 12:44:45 EEST 2011
Thu Jul 21 12:44:45 EEST 2011

$ echo <(date) <(date) <(date)
/proc/self/fd/11 /proc/self/fd/12 /proc/self/fd/13
`

İşlem değiştirmeyi (bir dosya oluşturan) ve giriş yeniden yönlendirmesini (bir dosyayı STDIN'e bağlayan) birleştirmek mümkündür:

`
$ cat < <(date)
Thu Jul 21 12:46:22 EEST 2011
`

Hemen hemen aynı görünüyor ama bu sefer kedi bir dosya adı yerine STDIN akışından geçti. Bunu echo ile deneyerek görebilirsiniz:

`
$ echo < <(date)
<blank>
`

echo STDIN'i okumadığından ve hiçbir argüman iletilmediği için hiçbir şey alamıyoruz.

Borular ve giriş yönlendirmeleri, içeriği STDIN akışına iter. İşlem ikamesi komutları çalıştırır, çıktılarını özel bir geçici dosyaya kaydeder ve ardından komut yerine bu dosya adını iletir. Hangi komutu kullanırsanız kullanın, onu bir dosya adı olarak kabul eder. Oluşturulan dosyanın normal bir dosya olmadığını, ancak artık gerekmediğinde otomatik olarak kaldırılan adlandırılmış bir kanal olduğunu unutmayın.

Komut ikamesi `<(komut)` ve `>(komut)` şeklinde kullanılabilir. Her form, işletim sistemine bağlı olarak, /tmp veya /var/tmp altında bir FIFO oluşturulmasına neden olur veya adlandırılmış bir dosya tanımlayıcısı (/dev/fd/*) kullanır. Yerine koyma sözdizimi, FIFO veya FD file descritptor adıyla değiştirilir ve içindeki komut arka planda çalıştırılır.

Değiştirme parametre genişletme ve komut ikamesi ile aynı anda yapılır yani aynı önceliğe sahiptir.

Bu özelliğin en yaygın kullanımlarından biri, geçici dosyaların oluşturulmasını önlemektir.

Örneğin aşağıdaki iki komut aynı görevi yapar

`jsx
diff <(sort list1) <(sort list2)
`

`jsx
mkfifo /var/tmp/fifo1
mkfifo /var/tmp/fifo2
sort list1 >/var/tmp/fifo1 &
sort list2 >/var/tmp/fifo2 &
diff /var/tmp/fifo1 /var/tmp/fifo2
rm /var/tmp/fifo1 /var/tmp/fifo2
`

<(...) ve >(...) arasındaki fark, yalnızca yönlendirmelerin hangi yolla yapıldığıdır. <(...) ile birinin ikameden okuması beklenir ve komut bunu stdout olarak kullanmak üzere ayarlanır. >(...) ile birinin ikameye yazması beklenir ve içindeki komut onu stdin olarak kullanmak üzere ayarlanır.

OLMADIK YERDE OLMADIK BİLGİYİ VERME GEREĞİNDEN FAZLA BİLGİNİN HENÜZ ÖĞRENİLMEYEN KONULAR OLDUĞUNDA BİR ÖNEMİ YOK !!!

Pipe ile işlem ikamesi performans karşılaştırma;[https://unix.stackexchange.com/questions/127645/performance-differences-between-pipelines-and-process-substitution?rq=1](https://unix.stackexchange.com/questions/127645/performance-differences-between-pipelines-and-process-substitution?rq=1)

Örneğin komut çıktılarını değişkenlere atamak istiyorsanız komut ikamesi kullanabilirsiniz. Komut ikamesi çıktıları tekrar standart input olarak kullanılır. Komut gruplarının çıktıları ise doğrudan standart çıktıya bastırılır. Bu sebeple komut ikamesi ile komutların çıktılarını değişkenlere tanımlayabilirken, komut gruplamanın sonucundaki çıktıları doğrudan değişken olarak tanımlayamayız.

İşlem ikamesi komutun çıktılarının okunabileceği bir dosya ismi ile değiştirilirken, komut ikamesi komutun çıktıları ile değiştiriliyor. Bu sebeple örneğin 

echo $(ls)

komutunu girdiğimizde ls komutunun çıktılarını alıyorken

echo <(ls) 

komutunu girdiğimzide /dev/fd/63 gibi bir çıktı alıyoruz. Buradaki çıktı bu komutun çıktılarının okunabileceği dosyanın ismidir. echo komutu daha önce de değindiğimiz şekilde dosyadan okuma yapmadığı için doğrudan dosyanın ismi konsola bastırılıyor. Aynı örneği cat komutu ile yapsak cat komutu dosyayı okuyacağı için çıktıları alacağız.

cat <(ls)

bakın ls komutunun çıktılarını alabildik çünkü cat komutu işlem ikamesinin verdiği dosyayı okudu ve dosya içeriğini konsola bastırdı. zaten işlem ikamesinin kullanım amacı geçici dosyalara gerek kalmadan kısayoldan işlerimizi halledebilmemizdir. 

Hatta komut ikamesini cat komutu ile kullanırsak, ls komutunun çıktıları cat komutuna argüman olarak verileceği için cat komutu bunların okunması gereken dosya olduğunu sanacak. Hemen komutumuzu girelim

cat $(ls)

bakın ls komutunun çıktılarında yer alan ifadeler cat komutuna okunması gereken dosya ismi olarak ulaştığı için cat komutu bunların bulunmadığını söylemiş oldu. Zaten cat komutunun ardından girdiğimiz yalın argümanın okunması gereken dosya olarak algılandığını daha önce de belirtimiştik.

Standart girdiden okuması için <<< kullanabiliriz örneğin.

Konuyu çok fazla dağıtmak istemiyorum ancak bu anlatımda dikkat etmenizi istediğim, öğrendiğimiz tüm bilgilerin yeri geldiğinde yeni bilgileri kavrayabilmek için ne kadar önemli olabildiğini görmüş olduğumuzdur. echo komutunun ve cat komutunun çalışma şekillerini bildiğimizde ve komut ikamesi ile işlem ikamesinin davranışlarını bildiğimizde doğru şekilde komut girip doğru sonuçlara ulaşmamız mümkün oldu. Bu komutların ve yapıların davranışlarını bilmiyor olsak yani ezbere bilgi sahibi olsak tam olarak istediğimiz sonuçları elde edemeyebiliriz. İşte ben de bu sebeple belki biraz sıkıcı veya gereksiz gibi gözüken ama ileride işimize yarayacak olan tüm temel bilgileri aktarmaya gayret ediyorum. Bu sayede çok daha bilinçli bir sistem yöneticisi olabiliriz. 

# İşlem Kontrolü

İşlemlerin nasıl oluştuğundan ve diğer temel kavramlardan bahsettik. Yani artık işlemin temelde ne olduğunu biliyoruz. Şimdi de işlemleri nasıl yönetebileceğimizden bahsederek devam edelim.

Sistemde başlatılan tüm işlemlerin benzersiz işlem numaralarına yani pid lere sahip olduğunu daha önce vurguladık. İşlemler bu benzersiz numaralar tarafından kontrol edildiği için sistem üzerinde oluşturulan tüm işlemlerin benzersiz işlem numarası vardır. İlk işlem olan init işleminin işlem numarası 1 olarak tanımlanır ve daha sonra init altında başlatılan tüm işlemler de sırasıyla boştaki işlem numaralarından birine sahip olur. Bu sayede işlem numaraları üzerinden hem çekirdek hem de bizler işlemler üzerinde kontrol sahibi olabiliyoruz. İşlemleri kontrol edebilmek için de sinyal mekanizmasını kullanıyoruz. Peki ama buradaki sinyal de ne demek ?

## Sinyaller

Sinyaller, belirli davranışları tetiklemek için çalışan bir işleme gönderilen standartlaştırılmış mesajlardır. Diğer bir tanımı, Sinyaller, önemli bir olayın meydana geldiğini belirtmek için bir programa gönderilen yazılım kesintileridir. Aslında sinyal işlemler arası haberleşme yöntemidir. Örneğin bir işlemin işlemin durmasını, durmakta olan işlemin devam ettirilmesini veya işlemin sonlandırılmasını belirtebileceğimiz çeşitli sinyaller mevcuttur. Bizler sinyalleri kullanarak işlemleri yönetebiliriz. İşlemleri yalnızca kullanıcıların gönderebileceğini de düşünmeyin lütfen. İhtiyaç halinde kullanıcılar tarafından gönderilebileceği gibi sistem tarafından da programlara gönderilebilirler. Zaten işlemler arasında iletimi mümkün olduğu için önceden tanımlanmış olan mesajların iletilmesi işlemidir. Tanımı çok iyi yapamamış olabilirim, ancak örnekler üzerinden kolayca anlayabileceksiniz merak etmeyin. Öncelikle mevcut sistemimizde tanımlı olan sinyallerin listesini görebilmek için kill komutunun -l seçeneğini kullanalım. Bakın numaraları ile birlikte pek çok işlem de listelenmiş oldu. Bu işlemleri açıklamadan önce kill komutunun işlevine de açıklık getirelim. Eğer daha önce linux ile ilgili bir eğitime katıldıysanız veya linux işletim sistemini kullandıysanız `kill` komutunun işlevini, çalışan işlemleri sonlandırmak olarak biliyor olabilirsiniz. Ancak bu tam olarak doğru değil, sadece en yaygın kullanımı bu şekilde olduğu için "`kill`" komutu, işlem sonlandırmada görevlidir" diye genel tanım yapılır. `kill` komutunun esas işlevi, sinyallerin çağırılmasını sağlamaktır. Nitekim kill komutunun l seçeneği ile tüm sinyalleri listeleyebildik. 

Görebildiğiniz gibi burada pek çok farklı sinyal bulunuyor. Elbette hepsine tek tek değinmeyeceğiz çünkü temel birkaç sinyal dışında diğer sinyallere neredeyse hiç ihtiyacımız olmayacak. Eğer merak ettiğiniz veya ihtiyaç duyduğunuz bir sinyal olursa manuel sayfalarından sinyallerin açıklamalarına göz atabilirsiniz. Ben yalnızca temel sinyallerden bahsetmek istiyorum.

Örneğin çalışmakta olan bir işlemi sonlandırmak istersek buradaki term sinyalini kullanabiliriz.

Ben örnek gösterebilmek adına yeni bir konsol penceresi daha açmak istiyorum. Şimdi bu konsola basit bir örnek olması açısından sleep 111 komutunu girelim. Bu komut sayesinde 111 saniye boyunca sleep işlemi çalışıyor olacak. Eğer ben bu işlem kendiliğinden kapanmadan önce bu işlemi sonlandırmak istersem kill komutunun ardından TERM sinyalini belirtip ardından da bu işlemin sinyal numarasını girmem yeterli. Bunun için öncelikle bu işlemin işlem numarasını öğrenelim. Çalışmakta olan işlemlerin isimleri üzerinden işlem numarasını öğrenmek için pgrep aracını kullanabiliyoruz. Tıpkı grep komutunda olduğu gibi bu aracımız da çalışmakta olan işlemlerde filtreleme yapıyor. Ben sleep işleminin işlem numarasını bulmak istediğim için komutumu pgrep sleep şeklinde giriyorum. Bakın sleep işleminin işlem numarası buymuş. Şimdi bu işlemi sonlandırmak adına kill TERM işlem-numarası şeklinde komutumu girebilirim. Komutumun hemen ardından bu işlem sonlandırıldı. Teyit etmek için tekrar pgrep komutu ile sleep işlemini sorgulayabiliriz. Bakın herhangi bir çıktı almadık çünkü aktif olarak çalışmakta olan bir sleep işlemi bulunmuyor. Dilerseniz ps au komutu ile de sleep işleminin çalışıp çalışmadığını teyit edebilirsiniz. Neticede kill komutu ile TERM sinyalini bu işleme göndermiş olduk ve dolayısıyla bu işlem terminate yan sonlandırılmış oldu. Bu noktada değinmek istediğim detay, eğer istersek buradaki sinyali farklı biçimlerde de tanımlayabiliriz. Tekrar kill -l komutu ile sinyal listesini alalım. Bakın burada TERM sinyali SIGTERM olarak geçiyor ve numarası 15. Yani bizler istersek kill TERM şeklinde yazmak yerine kill SIGTERM ya da kısaca kill -15 şeklinde de bu sinyali çağırabildik. Zaten genellikle sinyallerin sayısal karşılıkları daha kısa olduğu için daha sık tercih ediliyor. Ancak neticede buradaki tüm sinyalleri kill komutuna sayısal veya isimleri ile belirtebiliyoruz. 

İlk örneğimizde işlemi sonlandırmayı ele aldık. Şimdi de bir işlemi öldürmeyi deneyelim. Bir işlemi sonlandırmak ile öldürmek arasındaki fark, işlemleri term siyanli ile sonlandırırken işleme artık kapanması gerektiğini belirtiyor olmamızdır. Kill sinyali ile yani işlem öldürme sinyalinde ise doğrudan ilgili işlemi sonlandırmak için kullanıyor. Eğer bir işlem yanıt vermiyorsa term sinyaline de yanıt vermeyecektir. Bu durumda kill sinayli ile ilgili işlemin yanıt beklemeksizin öldürülmesi gerekir. İşte term ile kill sinyalleri arasındaki fark budur. Eğer bir işlemi beklemek istemiyorsanız veya yanıt vermiyorsa pek sağlıklı olmasa da kill sinayli ile doğrudan öldürebilirsiniz. 

Normalde bir işlemin doğru şekilde sonlandırılabilmesi için örneğin kaydedilmemiş verilerin veya değişikliklerin tamamlanıp kaydedilebilesi gibi yarım kalan işlerin sorunsuzca sonlandırılabilmesi için term sinyalinin kullanılması çok daha sağlıklı bir yaklaşımdır. Ancak bir işlem yanıt vermiyorsa veya işlemin sonlandırılması için bekleyecek kadar vaktiniz yoksa kill ile ilgili işlemi doğrudan öldürebilirsiniz.

Ben yine örnek olarak sleep 100 komutu ile yeni bir işlem başlatmak istiyorum. Şimdi bu işlemin işlem numarasını pgrep komutu ile öğrenelim. Pgrep sleep şeklinde yazıyorum. Bakın işlem numarası buymuş. Şimdi bu işlemi öldürmek için killl komutunun ardından KILL şeklinde de yazabiliriz ya da doğrudan öldürme sinyalinin karşılığı olan 9 sayısını tire işaretinden sonra -9 şeklinde de belirtebiliriz. Son olarak da elbette sinyalin gönderilecek işlemin numarasını belirtmemiz yeterli. Evet böylelikle sleep işlemi öldürüldü. Teyit etmek için yine ps au komutunu kullanabiliriz. Bakın çıktılarda sleep işleminin çalışmadığını görebiliyoruz.

Belki sleep komutu üzerinden term ve kill işlemlerinin farkı anlaşılamamış olabilir ancak yanıt vermeyen bir işlem ile karşılaştığınızda term sinyali yerine kill sinyalinin işlemi sonlandırdığını bizzat deneyimleyeceksiniz. 

Evet işlemleri sonlandırmak ve öldürmekten bahsettiğimizde göre şimdi de işlemleri nasıl arkaplana alabileceğimizden ve gerektiğinde nasıl durdurup tekrar devam ettirebileceğimizden de bahsedelim. Öncelikle bir işlemi nasıl arkaplanda başlatabileceğimize değinerek başlayabiliriz.

Bir işlemi arkaplanda başlatmak için tek yapmamız gereken komutun sonuna "ve" yani ampersant işaretini eklemedik. Bu sayede ilgili komutun oluşturacağı işlem mevcut kabuk altında bir alt kabuk başlatılarak bu alt kabuk üzerinde arkaplanda çalıştırılıyor olacak. Böylelikle ana kabuğa yeni komutlar girebilmeye devam edeceğiz. Normalde kabuğa standart şekilde bir komut girdiğimizde, komutun oluşturduğu işlem bitene kadar yeni komutlar giremeyiz çünkü mevcut kabuk bu işlemin bitmesini bekliyordur. Hemen denemek için sleep 30 şeklinde komutumuzu girelim. Bu sleep işlemi 30 saniye boyunca çalışacağı için bash kabuğu bu işlem bitene kadar yeni komutları işleyemeyecektir. Hemen denemek için echo deneme şeklinde yazalım ve komutu onaylaylım. Bakın komutu enter ile onaylamış olmama rağmen konsola bir çıktı bastırılmadı. sleep işlemi bitene kadar biraz bekleyelim. Bakın echo komutu sleep işlemi bittikten sonra çalıştırıldı. Çünkü ana kabuğumuz sleep işlemini bekliyordu. Dolayısıyla yeni komutları kabul edemedi. Kabuğun standart çalışma yapısı bu şekilde. Ancak söz konusu sistemi kabuk üzerinden yönetmek olduğunda elbette kabuk üzerinde yalnızca tek bir işlem başlatıp o işlem sonlanana kadar yeni komutlar giremiyor olmak kesinlikle verimli değildir. Bu duruma çözüm olarak işlemleri arkaplanda başlatabiliriz. Bu sayede mevcut kabuk arkaplandaki işlemleri beklemek zorunda olmayacağı için bizden yeni komutlar almaya ve dolayısıyla yeni işlemler baştlamaya devam edebilir. Hadi gelin sleep işlemini arkaplanda başlatmayı deneyelim. İşlemleri arkaplanda başlatmak için ampersant işaretinin kullanıldığından bahsetmiştik. Tek yapmamız gereken komutun sonuna eklemek. Ben sleep 60 & şeklinde yazıyorum ve komutumu onaylıyorum. Bakın burada ilgili işlemin işlem numarası bastırıldı yani işlemin arkaplanda başlatıldığını biliyorum. Emin olmak için echo deneme şeklinde yazıp onaylaylım. Bakın echo komutunun çıktısını anında alabildim. Hatta emin olmak için ps au komutu ile sleep işleminin çalışıp çalışmadığını da sorgulayabiliriz. Bakın sleep işlemi aktif olarak çalışmakta olan işlemler listesinde yer alıyor. Görebildiğiniz gibi işlemleri arkaplanda başlatarak mevcut kabuk üzerinde aynı anda birden fazla işlem çalıştırabiliyoruz. Sizler de bu şekilde istediğiniz kadar işlemi arkaplanda başlatabilirsiniz. Bu sayede mevcut kabuğa yeni emirler vermeye de devam edebilirsiniz. 

Ayrıca merak etmeyin arkaplandaki işlemlere de aynı şekilde sinyaller gönderebilirsiniz. Sinyal göndermek için tek yapmanız gereken ilgili işlemin işlem numarasını bilmektir. 

Arkaplanda başlatmayı öğrendik, peki ama ya bir işlemi başlattıktan sonra arkaplana almak istersek ne yapmamız gerekiyor ? Yani bir işlemi başlattıktan sonra fikrimiz değişebilir ve önplanda çalışmakta olana işlemi arkaplana almak isteyebiliriz. Bu durumda öncelikle çalışmakta olan ilgili işlemi duraklatmamız gerekiyor. Duraklatma işlemi için işleme duraklatma sinyali olan STOP sinyalini gönderebiliriz. Ancak mevcut kabuk önplanda çalışmakta olan işlem ile meşgul olduğu için yeni bir konsol penceresine yani yeni bir kabuğa geçip sinyali oradan göndermemiz gerekiyor. Elbette bu yaklaşım pek pratik olmadığı için bu duruma çözüm olarak ctrl z kısayolu sunulmuştur. Eğer önplanda çalışmakta olan bir işlemi durdurmak istersek tek yapmamız gereken ctrl z kısayolunu kullanmaktır. Hemen denemek için sleep 111 şeklinde komutumuzu girelim. Bakın şu anada bu işlem mevcut kabuk üzerinde önplanda çalışıyor dolayısıyla bu işlem bitmeden yeni komutlarımız kabuk tarafındna işlenemeyecek. Bu işlemi durdurmak için ctrl z tuşlamasını uygulayalım. Bakın işlemin durdurulduğuna dair çıktımızı da aldık. Artık mevcut kabuğumuza yeni komutlar girebiliriz. Ben durdurmuş olduğum işlemi arkaplana almak istediğim için background ifadesinin kısalması olan bg komutunu giriyorum. Bu sayede en son duraklatılmış işlem bg komutu ile arkaplanda çalışama devam ediyor. Zaten bakın burada sleep işleminin sonuna arkaplana alma işlevinde olana ampersant operatörü de eklenmiş gözüküyor. Ayrıca ps au komutu ile bu işlemin çalışmakta olduğunu teyit edebiliriz. Eğer arkaplana aldığımız işlemi tekrar önplana almak istersek de foreground ifadesinin kısalması olan fg komutunu kullanabiliriz. Bakın arkaplanda çalışmakta olan en son işlem tekrar önplana alınmış oldu. Ben en son işlemler olduğu için özellikle arkaplana alınacak veya ön plana alınacak işlemleri belirtmedim ancak mevcut kabuk üzerinde birden fazla işlem olduğunda hangisi üzerinde işlem yapılması gerektiğini özel olarak belirtmemiz gerekiyor. 

Ben örnek olması için sleep 111 & sleep 222 & komutu ile arkaplanda iki sleep işlemini başlatıyorum. Eğer 111 saniye bekleyecek olan arkaplandaki işlemi ön plana almak istersem fg sleep 111 şeklinde komut girmem yeterli. Bakın arkaplandaki sleep 111 komutu önplanda çalışmaya başladı. Buna benzer örnekleri çoğaltabiliriz ancak temelde işlemleri nasıl arkaplanda başlatabileceğimiz veya daha sonradan arkaplana alıp gerektiğinde tekrar önplana alabileceğimizi öğrendik. Özetleyecek olursak; arkaplanda başlatmak için komutun sonuna ampersant operatörünü ekliyoruz. Eğer çalışmakta olan bir işlemi arkaplana almak istersek de öncelikle bu işlemi durdurmamız gerekiyor. Durdurmak için de harici bir konsoldan kill STOP işlem numarası ile ya da daha kolay şekilde işlemin çalışmakta olduğu konsol üzerinden ctrl z tuşlaması yaparak ilgili işlemi duraklatabiliyoruz. İşlem duraklatıldıktan sonra işlemin çalıştırıldığı kabuk üzerinden arkaplana almak istediğimiz için bg komutunu kullanıyoruz. Eğer aynı kabuk üzerinde birden fazla işlem duraktlatıldıysa bg komutunun ardından arkaplana alınmasını istediğimiz işlemi spesifik olarak belirtmemiz gerekiyor. Bu sayede duraklatılmış olan işlem arkaplanda çalışmaya devam ediyor. Arkaplanda çalışmakta olan işlemi tekrar önplana almak istediğimizde ise fg komutunun arından ilgili işlemin tam ismini belirtmemiz yeterli oluyor. Önplandaki işlemler ve arkaplandaki işlemler hakkında şimdilik bu kadarlık bilgi yeterli. 

Şimdi yaygın kullanıma sahip bir diğer sinyal olan kesme sinyalinden de kısaca bahsetmek istiyorum. Mevcut kabuk üzerinde bir işlemi duraklatmak yerine doğrudan keserek sonlandırmak istersek interrtup ifadesinin kısalmasından gelen INT sinyalini kullanabiliriz. Elbette aktif olarak çalışmakta olan bir işlemi kesmek isteyeceğimiz için harici bir konsola ihtiyaç kalmaması adına bu sinyali de ctrl c kısayolu ile kullanabiliyoruz. Örneğin bir paketi kurmak için komut girdiniz ancak paket yüklenirken yanlış paket olduğunu fark ettiniz veya herhangi bir sebeple bu işlemi sonlandırmak istediniz. Bu durumda harici bir konsol üzerinden işlemi sonlandırmak için komut girmek pek pratik bir yaklaşım değildir. Bunun yerine ctrl c kısayolunu kullanarak önplanda çalışmakta olan mevcut işleme kesme sinyali gönderip ilgili işlemin sonlandırılmasını sağlayabilirsiniz. Bu kısayol özellikle önplandaki işlemleri ani olarak sonlandırmak istediğimizde oldukça kullanışlıdır. Ben denemek için konsola sudo apt install python2 şeklinde yazıyorum ve komutumu onaylıyorum. Ve yükleme işlemi sırasında işlemi sonlandırmak istediğim için de ctrl c kısayolunu kullanıyorum. Bakın önplandaki bu işlemi kolayca sonlandırmış oldum. Sizler de önplandaki işlemleri gerektiğinde sonlandırabilmek için bu ctrl c pratik kısayolunu kullanabilirsiniz.

Tüm bunlar dışında bir de mevcut konsol kapatılırken konsol tarafından işlemleri sonlandırmak için gönderilen kapatma sinyaline karşı koymak için de birkaç farklı yoldan bahsetmek istiyorum.

Konsol kapatılırken mevcut konsol üzerinden çalıştırılmış olan tüm işlemlere otomatik olarak HUP kapatma sinyali gönderiliyor. Yani örneğin ben mevcut konsol üzerinden arkaplanda bir işlem başlattığımda konsolu kapatırsam bu işlem de otomatik olarak sonlandırılıyor. Eğer başlatılan işlemler çalışmaya devam etsin istersek HUP sinyaline karşı koruma mekanizmasını kullanmamız gerekiyor. İşlemi başlatırken ve işlemi başlattıktan sonra olmak üzere iki tür koruma yöntemi bulunuyor. Öncelikle bir işlemi nasıl konsolun kapatma sinyaline karşı koruyabileceğimizi ele alalım.

Using `&` causes the program to run in the background, so you'll get a new shell prompt instead of blocking until the program ends. `nohup` and `disown` are largely unrelated; they suppress SIGHUP (hangup) signals so the program isn't automatically killed when the controlling terminal is closed. `nohup` does this when the job first begins. If you don't `nohup` a job when it begins, you can use `disown` to modify a running job; with no arguments it modifies the current job, which is the one that was just backgrounded

Ben kolay takip edilebilir bir örnek olması için grafiksel arayüze sahip bir aracı örnek olarak kullanacağım. Siz istediğiniz bir uygulamayı kullanabilirsiniz, ben sistemimde yüklü bulunan gedit isimli metin düzenleme aracını açmak üzere konsola gedit yazıyorum. Bakın gedit aracı grafiksel arayüzde açıldı. Şimdi bu aracı çalıştırdığım konsolu kapatırsam ne olacağını görelim. Bakın kapatmak istediğimde terminalde çalışmakta olan işlemlerin öldürüleceği belirtiliyor. Ben kapatmak üzere tıklıyorum. Bakın terminal ile birlikte açmış olduğum araç da anında kapatıldı. Aynı örneği bu kez gedit aracını arkaplanda başlatıp da deneyebiliriz. Bunun için yeni bir terminal açalım. Şimdi komutumuzu gedit & şeklinde yazalım. Bakın aracımız arkaplanda çalışmaya başladı. Şimdi yine terminal penceresini kapatmayı deneyelim. Bakın anında hem terminal hem de çalıştırılan araç kapatıldı. Çünkü terminal kapatılırken çalıştırmış olduğu tüm işlemeler HUP sonlandırma sinyali otomatik olarak gönderiliyor. Eğer bu sinyalin ilgili işleme ulaşmasını engellersek terminal kapatılsa dahi araç çalışmaya devam edecek. 

Bir işlemi HUP sinyaline karşı bağışık olarak başlatmak istersek nohup komutunun ardından çalıştırılacak işlemin komutunu girmemiz yeterli. Zaten komutun isminde no hup yani hup yok anlamı yer aldığı için hatırlanması da çok kolay bir komut. Bakın aracım çalıştırıldı ve ayrıca konsol üzerinden de işlemin nohup ile başlatıldığını görebiliyoruz. Şimdi konsolu kapatmayı deneyelim. Bakın yine uyarı veriyor, ben yine de kapatıyorum. Ve görebildiğiniz gibi gedit aracı çalışmaya devam ediyor. Çünkü hup kapatma sinyali bu araca iletilmedi. Ben önplandaki işlem için uyguladım ancak aynı şekilde arkaplandaki işlemleri de nohup ile hup kapatma sinyaline karşı koruyabilirsiniz. Hatta arkaplandaki işlem için de deneyelim aklınızda kuşu kalmasın. Yeni bir terminal penceresi açalım. Açılan pencereye de nohup gedit & şeklinde yazıp komutumuzu onaylayalım. Bakın aracım arkaplanda başlatıldı. Şimdi terminal penceresini kapatmayı deneyelim. Terminal penceresi sorunsuzca kapandı ve buna rağmen çalıştırmış arkaplandaki olduğum işlem hala çalışmaya devam ediyor. İşte sizler de bu şekilde terminala kapatılırken gönderilen hup kapatma sinyaline karşı dirençli olan işlemleri başlatabilirsiniz. 

ÖZELLİKLE SSH GİBİ UZAK MASAÜSTÜ BAĞLANTISINDA EĞER BAĞLANTI KOPARSA İLGİLİ İŞLEM ARKAPLANDA BAŞLATILMIŞ OLSA BİLE HUP SİNYALİNDEN DOLAYI İŞLEMİN TAMAMLANMAMA İHTİAMLİ VAR. BU SEBEPLE GEREKTİĞİNDE HUP SİNYALİNE KARŞI DİRENÇLİ İŞLEMLER BAŞLATMAK ÇOK ÖNEMLİDİR.

Eğer bir işlemi başlatırken hup sinyaline karşı dirençli olarak başlatmadıysanız daha sonradan da dirençli hale getirebilirsiniz. Ancak bunun için ya işlemi arkaplanda başlatmış olmanız ya da arkaplanda başlatmadıysanız da durdurup arkaplana almanız gerekiyor. Ben gedit & komutu ile işlemi arkaplanda başlatıyorum. Eğer bu şu durumda konsolu kapatırsam bu arkaplandaki işlemin de kapatılacağını zaten biliyoruz. Bunu önlemek için disown komutunun ardından bu arkaplandaki işlemin işlem numarasını belirtmem yeterli. İşlem numarası zaten burada çıktı olarak verilmiş, bunu disown komutunun ardından giriyorum. Tamamdır ardık bu işlem de hup kapatma sinyaline karşı dirençli hale geldi. Denemek için konsolu kapatabiliriz. Bakın konsol kapanmış olmasına rağmen işlem sorunsuzca çalışmaya devam ediyor. Görebildiğiniz gibi işlemleri yalnızca başlatırken değil daha sonraki kararımız ile de hup kapatma sinyaline karşı koruyabiliyoruz. Eğer siz bir işlemi arkplanda başltmadıysanız zaten daha önce de değindiğimiz şekilde durdurup arkaplana alabilir ve o arkaplandaki işlemi disown komutu ile hup kapatma sinyaline karşı dirençli hale getirebilirsiniz. 

Örneğin bir aracı konsol üzerinden çalıştırdınız ancak daha sonra konsolu kapatmak istediniz diyelim. İşte disown komutunu kullanarak konsol kapandıktan sonra da ilgili işlemin çalışmaya devam edebilmesini sağlayabilirsiniz.

En temel sinyallerden bahsettiğimize göre şimdi de sinyalleri gönderirken bizlerin işini kolaylaştıran pkill ve killall araçlarından da kısaca bahsedebiliriz. Bu araçlar sayesinde çalıştırılan işlemlerin isimleri üzerinden sinyal gönderebiliyoruz. Yani işlemlerin işlem numaralarını öğrenmeye gerek kalmadan yalnızca isimlerini de kullanmamız mümkündür.

KİLL KOMUTUNUN VARSAYILAN OLARAK TERM SİNYALİ GÖNDERİYOR BUNU DA EKLE

Sinyallerin yazılım kesintileri olduğunu ve USR1 USR2 gibi sinyallerin yazılım geliştirilcileri tarafından keyfi olarak tanımlanmış anlamları olduğunu biliyoruz. Bu sinyaller dışında diğer sinyallerin daha önceden belirtlenmiş katı kuralları vardır. Örneğin bir işlemi sonlandırmak veya durdurmak gibi tanımlar, tüm işlemlerde ortak olarak geçerlidir. Ancak USR1 ve USR2 sinyalleri, gönderildikleri yazılımın geliştiricisi tarafından belirtirlmiş olan değişken davranışı gösterir. 

Örneğin benim aklıma ilk olarak dd aracına gönderebileceğimiz USR1 sinyali geliyor. Diyelim ki dd aracını kullanarak bir imaj oluşturmak istedik ve işlemi arkaplanda başlattık. Yani işlemin ilerleyişini konsol üzerinden takip edemiyoruz. BU durumda dd aracına USR1 sinyalini gönderirsek dd aracı çalışmasını durdurmadan o andaki ilerleme durumu hakkında bilgi sunacaktır. 

Ben denemek için dd if=/dev/zero of=/dev/null & komutu ile işlemi arkaplanda başlatıyorum. Şu anda dd aracı sıfırları hiç bir yer olarak bilinen sanal dosyaya yazmaya devam ediyor ancak biz göremiyoruz. Görmek için yazılım kesintisi olarak USR1 sinyalini gönderebiliriz. Bu sinyali alan dd aracı bize o andaki durumu bildirecek. Hemen denemek için kill -s USR1 $(pidof dd) komutunu girelim.

Bakın dd aracının yazma durumu hakkında bilgi aldık. Üstelik bu çıktıyı alırken dd aracı durmadı, çalışmaya devam ediyor. Bu durumu gözlemelemek için tekrar sinyal gönderebilrim. Bakın biraz daha yazılmış yani işlem devam ediyor ancak USR1 sinyali sayesinde bilgi alabildik. DD aracı geliştiricisi tarafından bu sinyali aldığında durum bilgisini konsola bastıracak şekilde programlanmış. Başka bir araç usr1 sinyalini aldığında başka şekilde davranır. Çünkü usr1 ve usr2 sinyali tamamen geliştiricilerin insiyatifine bırakılmış sinyallerdir. Benim aklıma dd aracının davranışı geldiği için bu örneği verdim ancak farklı bir araç usr1 sinyaline farklı şekilde tepki verir veya geliştiricisi tarafından herhangi bir özellik tanımlanmadıysa hiç tepki de vermeyebilir. 

Yani buradaki sinyallerde katı ve keyfi olarak tanımlanmış olan özelliklerin açıklaması bu şekildedir. Katı olan sinyaller tüm işlemlerde aynı davranışı sergilerken, geliştiricilerin insiyatifine bırakılmş keyfi sinyaller ilgili yazılımın ihtiyaçlarıan göre tepki verir. 

# İşlemelere İsimleri Üzerinde Sinyal Göndermek

İsimler üzerinden sinyal gönderirken pkill ve killall komutları benzer işlevdedirler. Tek fark pkill aracının işlemin isminin bir kısmı yazılmış olsa da otomatik tamamlama yapıp bu isimle eşleşen tüm işlemlere sinyal gönderiyor olmasıdır. Killall komutu ile tam olarak belirtilen isimle eşleşen işlemlerin tamamına sinyal gönderiyor.

Şimdi net olması için firefox aracı üzerinden kullanımlarına değinmek istiyorum. Firefox aynı anda birden çok işlem çalıştırdığı için güzel bir örnek olabilir. Öncelikle firefox & komutu ile arkaplanda firefox tarayıcısını çalıştıralım. Tarayıcı açıldı.

Şimdi ben bu aracı kapatmak istersem işlem numarasına sinyal göndermem gerekiyor. Bunun için de öncelikle işlem numarasını öğrenmemiz gerekiyor. Öğrenmek için ps ax komutu ile sistem üzerinde çalışmakta olan tüm işlemleri listeleyebiliriz. Bakın listenin sonunda firefox için birden fazla işlemin çalışmakta olduğunu görebiliyoruz. Hatta istersek pidof komutunun ardından firefox şeklinde yazarak firefox işleminin geçtiği tüm işlemlerin numalarının konsola bastırılmasını da sağlayabiliriz. Buradaki pidof komutu da kolayca akılda tutulabilen bir komut. Çünkü örneğin ben pidof firefox şeklinde yazdığımızda ingilizce olarak process id of firefox yani firefox un işlem numarası gibi bir anlamı kast ediyorum. Yani pidof komutunun ismi buradan geliyor. pidof komutunun hemen ardından girdiğimiz argümanla eşleşen işlemlerin işlem numaralarını alabiliyoruz. 

Neticede görebildiğiniz gibi birden fazla işlem olduğu için firefox aracını sağlıklı şekilde sonlandırmak üzere tüm işlem numaralarına kapatma sinyali göndermemiz gerekiyor. Ana işleme de gönderebiliriz ancak sağlıklı bir sinyal gönderimi olabilmesi için tüm işlemelere göndersek daha iyi olabilir. Zira bazı araçların tam olarak kapatılması için veya aracın sorunsuzca kapatılması için tüm işlemlere aynı anda sinyal göndermemiz de gerekebilir.

pidof ya da ps ax komutu ile öğrendiğimiz tüm işlemlere kill komutu ile kapatma sinyali gönderebiliriz. Ancak aslında bundan çok daha pratik olarak pkill ya da killall komutlarını da kullanabiliriz.

Eğer pkill komutunun ardından kapatmak istediğimiz işlemin ismini girersek, pkill komutu bu isimle eşleşen tüm işlemlere sinyal gönderecek. Tıpkı kill komutunda olduğu gibi ek olarak bir sinyal belirtmediğimizde 15 sinyal numarasını yani terminate sinyalini gönderiyor. Ben denemek için pkill firefox şeklinde komutumu giriyorum. Komutumu girdim ancak hiç bir şey olmadı. Peki ama neden ?

Komutum çalışmadı çünkü firefox aracının işlem ismi sistem üzerinde doğrudan firefox olarak geçmiyor. Dolayısıyla pkill aracına firefox ifadesini argüman olarak verdiğimizde kapatılması gereken işlemi bulamadı. Bunun yerine -f seçeneğini de ekleyerek işlemlerin başlatılmasını sağlayan isim üzerinden araştırma yapılmasını sağlayabiliriz. Hemen komutumuza -f seçeneğin ekleyip tekrar girelim. Bakın firefox işlemi otomatik olarak sonlandırıldı. ps ax komutu ile de firefox işlemlerinin hepsinin sonlandırıldığı teyit edebiliyoruz.

Pkill aracı esasen daha önce de bahsetmiş olduğumuz pgrep aracını kullanarak işlemelerin isimleri üzerinden bulunup kolayca sinyal gönderilebilmesini sağlayan bir araçtır. Bu durumu teyit etmek için tekrar firefox & komutu ile arkaplanda firefox aracını başlatalım. Şimdi de pgrep firefox komutu ile firefox isminin geçtiği işlemlerin numalarını sorgulayalım. Bakın yine herhangi bir çıktı alamadık çünkü firefox ifadesi işlem ismi olarak geçmiyor. Eğer top komutu ile çalışmakta olan işlemlere bakacak olursak doğrudan firfefox isminin geçmediğini web ile ilgili işlem isimleri olduğunu görebiliyoruz. Şimdi pgrep aracımıza -f seçeneğini ekleyerek işlemin başlatıldığı komut ismi üzerinden araştırma yapmayı deneyelim. Bakın firefox ifadesi ile ilgişkili tüm işlemler konsola tek tek bastırıldı. İşte zaten pkill aracı da pgrep aracını kullandığı için -f seçeneğini kullanmak durumunda kalmıştık. Ayrıca buradaki örnek sizleri yanıtlmasın, bazı işlemlerin işlem isimleri de komut isimleri ile aynı olabilir. Bu durumda -f seçeneğini kullanmak zorunda da değilsiniz.

pkill aracı haricinde bir de benzer görevi gören killall komutunu da kullanabiliyoruz. Ancak pkill aracı işlemin isminin tamamı yazılmasa da otomatik olarak geri kalanını tamamlayıp eşleşen tüm işlemlere sinyal gönderebildiği için killall komutundan çok daha sık tercih ediliyor. Örneğin şu an çalışmakta olan firefox işlemini killall firefox komutu ile sonlandıramayız. Hemen deneyelim. Bakın komutun ardından bu isimde bir işlem bulunmadığı konusunda hata çıktısı aldık ve işlem halen çalışmaya devam ediyor. Çünkü işlemin isminde yalnızca firefox ifadesi bulunmuyor. killall komutu da otomatik olarak bu ifadenin kısmi olarak geçtiği işlemleri bulma yapısına sahip değil. Bu sebeple özellikle tam olarak ilgili işlemin başlatıldığı tam komut ismini girmemiz gerekiyor. Bu ismi öğrenmek için ps ax komutunu kullanabiliriz. Bakın burada /usr/lib/firefox/firefox ifadesi bulunuyor. Bu işlem ana işlem olduğu için bu ismi girdiğimde ilgili işlemi ismi üzerinden sonlandırmış olacağım. Hemen killall komutundan sonra bu ismi yazalım. Bakın firefox aracı anında sonlandırılmış oldu. 

İşte burada ele aldığımız firefox öğrenğinde de gördüğümüz üzere, işlemleri isimleri üzerinden sonlandırmak için killall veya pkill komutlarının her ikisini de kullanabiliyoruz. Fakat pkill komutu genellikle killall komutuna oranla çok daha kullanışlı olabiliyor. Killall komutunu spesifik olarak aynı ifadenin tamamının bulunduğu bir işlemi sonlandırmak istediğimiz durumda kullanabiliriz.

Ayrıca ben hep standart şekilde kullandım ancak dilerseniz pkill komutunun ve killall komutunun hemen ardından göndermek istediğiniz sinyali belirtmeniz yeterli. Normalde varsayılan olarak term sinyali gönderiliyor ancak sizler örneğin pkill -9 işlem-ismi veya killall -9 işlem-ismi şeklinde yazarak öldürme sinyalini istediğini işleme yönlendierbilirsiniz. Burada 9 yani kill sinyali yerine dilediğiniz bir sinyali dilediğiniz şekilde kullanabilirsiniz.

Esasen killall ve pkill komutlarının işlemleri filtreleyebileceğiniz çeşitli seçenekleri de bulunuyor. Bu seçenekleri görmek için komutun ardından —help şeklinde yazmamız yeterli. Örneğin killall aracının yardım çıktılarına kısaca göz atabiliriz. Bakın burada isim araştırması sırasında küçük büyük harflerin görmezden gelinmesi için -i seçeneğinin kullanılabileceği belirtilmiş. Ayrıca işlemleri önce veya sonra başlatılma durumlarına göre buradan younger veya older seçenekleri ile de filtreleyebiliyoruz. Örneğin younger seçeneği yani y seçeneği kullanılırsa en yeni başlatılmış olan işleme sinyal gönderilmesini sağlayabiliriz. Bunun dışında kullanıcı özelinde işlem isimlerinin araştırılmasını da sağlayabiliyoruz. Örneğin sistem üzerinde aynı anda birden fazla kullanıcı aktif olabilir. Ve bu kullanıcıların hepsi aynı anda firefox işlemini başlatmış ve kullanıyor olabilir. Eğer ben tüm kullanıcılar yerine yalnızca ahmet isimli kullanıcının sistemindeki firefox isimli işlemine sinyal göndermek istersem komutumu sudo killall -u ahmet firefox şeklinde girebilirim. Buradaki sudo komutu önemli çünkü ancak root kullanıcısı başka kullanıcıların işlemlerine müdahale edebilir. Yani normalde hiç bir kullanıcı bir başka kullanıcının çalıştırmış olduğu işleme sinyal gönderme gibi müdahalelerde bulunamaz. Bu zaten aynı anda birden fazla kullanıcının birbirinden izole ve güvenli şekilde sistemi kullanabilmesi için elzem olan doğal bir yaklaşımdır. Sizler de sistem yöneticisi olarak yalnızca root yetkilerine erişiminiz varken diğer kullanıcıların işlemlerine müdahale edebileceğinizi unutmayın lütfen.

Bunun dışında diğer seçenekleri ek olarak açıklamaya gerek yok. pkill aracının yardım sayfasına da göz attığımızda benzer seçeneklerin bulunduğunu görebiliyoruz. Konuyu çok fazla uzatıp canınızı sıkmak istemiyorum. Tek yapmanız gereken burdaki seçenekleri deneme yanılma yoluyla bizzat test etmenizdir. Elbette tüm seçeneklere her zaman ihtiyacınız olmayacak. İşlemlerin başlatılma önceliği ve kullanıcılara özel olan filtreleme gibi işlevler dışında diğer seçeneklere sık ihtiyaç duyabileceğiniz durumlarla karşılaşmazsınız. 

Neticede işlemin temelde ne olduğunu ve işlemlere nasıl sinyal göndererek yönetebileceğimizi artık biliyoruz. Sinyal gönderme işlevi söz konusu, özellikle sistem genelindeki tüm işlemleri yönetmek olduğunda kesinlikle ihtiyaç duyduğumuz bir çözüm. Bu sinyal mekanizmasına ek olarak, mevcut kabuk üzerinden başlatılmış olan işlemlerin çok daha pratik şekilde yönetilebilmesi için "iş" mekanizması da geliştirilmiştir. 

Mevcut kullanıcı hesabının daha kolay yönetilebilmesi için bash kabuğu da dahil olmak üzere pek çok modern kabuk, kendi altında çalıştırılan işlemlere bir "iş" gözüyle bakma yaklaşımına gitmiştir. Şimdi bu iş yaklaşımından bahsederek anlatıma devam edelim.

## Job Control | İş Kontrolü

Sinyaller sayesinde işlem numarasını kullanarak işlemleri istediğimiz şekilde yönetebiliriz. Ancak sistem üzerinde aynı anda pek çok işlem çalıştığı için istediğimiz bir işleme sinyal göndermek için o işlemin işlem numarasını öğrenmemiz gerekiyor. ps top pgrep ve benzeri araçlar ile işlemlerin numaralarını nasıl öğrenebileceğimizi ele aldık. Ancak bizzat deneyimlediğimiz gibi sistem üzerinde aynı anda birden çok işlem çalışmakta olduğu için işlemlerin numalarına ulaşmak için biraz çaba sarf etmemiz gereken durumlar olabiliyor. Örneğin firefox aracının birden çok işlem başlattığını ve işlem isminin sistem üzerinde farklı gözüktüğünü bizzat deneyimledik. Söz konusu tüm çalışmakta olan işlemlerde tam olarak istediğimiz işlemin numarasını bulmak olduğunda neticede biraz dikkatli olmamız ve bazen ekstra çaba sarf etmemiz gerekebiliyor. İşte tüm bu duruma karşın, kabuk kullanımında işlemlerin yönetimini kolaylaştırmak amacıyla kabuğa özgü olan "iş kontrol" mekanizması geliştirilmiştir.

Neticede kabuğun sistem yönetimi sırasında bizim işlerimizi kolaylaştırması gerekiyor. Zaten bu sebeple özellikle kabuk kullanıyoruz. İşte işlem kontrol mekanizması da kabuğun bizlere sunduğu pek çok kolaylaştırıcı özellikten biridir. Bash kabuğu hariç zsh gibi gelişmiş diğer pek çok kabukta da iş kontrol mekanizması vardır. Peki iş kontrol mekanizması tam olarak ne işe yarıyor ? 

İş kontrol mekanizması sayesinde mevcut kabuk üzerinden çalıştırılmış olan tüm işlemler mevcut kabuğa özel olan bir işlem tablosunda tutuluyor. Bu tablo üzerinden de ilgili işlemleri kolayca yönetebiliyoruz. Yani tüm sistemdeki işlemler yerine yalnızca mevcut kabuk üzerinden başlatılmış olan işlemleri yönetmek için bir kısayol tablosuna sahip oluyoruz. Bu sayede daha az işlem arasından doğru işlemi seçme ve istediğimiz şekilde yönetme kolaylığına sahip oluyoruz. Ayrıca zaten gerektiğinde sistem üzerindeki tüm işlemlere ulaşmak istediğimizde daha önce öğrenmiş olduğumuz ps top ve benzeri araçları da kabuk üzerinden kullanabildiğimiz için sistemin tam hakimiyetine de her zaman sahip oluyoruz. Yani iş kontrolünü lokal, işlem kontrolünü ise global olarak değerlendirebilirsiniz. Amacımıza göre pratik olan yaklaşımı seçmek bizim elimizde. Hemen daha net anlamak adına basit bir örnek vermek istiyorum.

Ben örnek olarak sleep 1111 | sleep 2222 | sleep 3333 & şeklinde komutumu giriyorum. Bu komutun neticesinde arkaplanda aynı anda çalışan 3 tane sleep işlemi oluşturuldu. Bu durumu teyit etmek için  pidof ya da pgrep komutlarını kullanabiliriz. Ben pgrep sleep şeklinde komutumu giriyorum. Bakın burada üç farklı işlem numarası listelendi. Eğer ben bu pipeline üzerindeki tüm işlemleri sonlandırmak istersem yani bu pipe hattını komple sonlandırmak istersem tüm işlemlere kapatma sinyali göndermem gerekiyor. Bunun yerine bu pipeline iş tablosuna eklendiği için iş tablosu üzerindeki ismi üzerinden de tüm işlemleri tek seferde sonlandırabilirim. Bakın burada işlemi arkaplanda başlattıktan hemen sonra [1] ve işlem numarası şeklinde bir çıktı almıştım. Buradaki 1 rakamı bu komutun oluşturduğu işlemlerin işlem toblosunda 1 numaralı sıraya yerleştirildiğini belirtiyor. Buradaki işlem numalarası da komutun oluşturduğu ilk işlemin numalarası.

Hatta iş tablosunu görmek için işler ifadesinin ingilizcesi olan jobs komutunu da kullanabiliriz. Bakın girmiş olduğumuz komutun 1 numarası ile tabloya eklendiğini ve bu komutun çalışma durumunu buradan görebiliyoruz. Komutun oluşturduğu işlemler şu anda çalışmakta olduğu için burada çalışma durumu belirtiliyor. Şimdi denemek için ben bu komutun oluşturduğu tüm işlemlere tek seferde durdurma sinyalini göndermek istiyorum. Bunun için kill komutunun ardından görndermek istediğim sinyali yani -STOP sinyalini yazmam ve iş tablosundaki hangi işi hedef gösterdiğimi belli etmek için de yüzde işaretinin ardından iş numarasını girmem gerekiyor. Benim girdiğim komut iş tablosunda ilk sırada olduğu için ben komutumu kill -STOP %1 şeklinde yazıp onaylıyorum. Herhangi bir çıktı almadık ama komutumuz başarıyla çalıştı. Teyit etmek için tekrar jobs komutunu kullanabiliriz. Bakın bu kez bu işin durdurulmuş olduğunu buradaki durum bilgisinden görebiliyoruz. Normalde pipeline üzerindeki tüm işlemleri durdurmak için tüm işlemlerin işlem numaralarını belirtmemiz gerekiyordu. Ancak iş tablosu sayesinde iş numarası üzerinden girdiğimiz komutun oluşturduğu tüm işlemlere aynı anda sinyal gönderebildik.

Bash kabuğu kendisine emir olarak verilmiş olan tüm komutların başlattıkları işlemleri iş tablosuna bu örneğimizde olduğu şekilde ekliyor. Bu sayede sistem üzerindeki tüm işlemler ile uğraşmadan çok daha pratik şekilde mevcut kabuk üzerinden başlatılmış olan işlemleri yönetebiliyoruz. Örneğin daha önce firefox & komutu ile arkaplanda başlatmış olduğumuz aracı kapatmak için biraz uğraşmıştık. Ancak iş tablosunu kullanarak kolayca bu işlemi sonlandırabiliriz. Bakın firefox işlemi 2 numaralı iş olarak tabloya eklenmiş. Bu işi sonlandırmak için kill %2 komutunu girmem yeterli. Bakın firefox aracı mevcut kabuk üzerinden başlatıldığı için iş tablosu üzerinden kolayca sinyal gönderebildim. 

İş tablosunun kullanımı hakkında birkaç örnek daha vereceğim ancak bundan önce, iş tablolarının yalnızca mevcut kabuğa özel olduğunu unutmayın. Yani örneğin ben yeni bir konsol penceresi açarsam yeni bir kabuk açılacağı için iş tablosu da boş olacaktır. Bakın şu anda bu kabuğun iş tablosunda pipeline işleminin duraklatılmış olduğunu jobs komutunun çıktılarında görebiliyoruz. Şimdi jobs komutunu yeni kabuk üzerinden girelim. Bakın herhangi bir çıktı alamadık. Çünkü daha önce de söylediğim şekilde, işlem tablosu mevcut kabuğa özgüdür. Yalnızca mevcut kabuk üzerinden girilmiş olan komutların oluşturdukları işlemler mevcut iş tablosuna eklenir ve bu iş tablosu üzerinden yönetilebilir. Örneğin ben bu yeni kabukta sleep 55& şeklinde komut giriyorum. Bakın bu işlem de işlem tablosuna 1 numaralı iş olarak eklendi. Hatta jobs komutu ile de teyit edebiliriz. Bakın her iki kabuğun 1 numaraları işi farkı gözüküyor çünkü her iki kabuk da birbirinden bağımsız. Zaten ben de bu sebeple iş yönetiminin lokal olduğunu işlem yönetimin global olduğunu belirttim. Yani sistem üzerinde çalışmakta olan tüm işlemlere yine tüm kabuklar üzerinden ps top gibi araçları kullanarak erişebiliriz. Örneğin yeni açtığım kabuk üzerinde ps au şeklinde komut girersem önceki kabuk üzerinden başlatılmış ve duraklatılmış olan sleep işlemlerini görebiliyorum.

Siz tüm sistem üzerindeki tüm işlemleri tek tek ele alıp yönetmek istiyorsanız işlem numaraları üzerinden yönetimde bulanabilirsiniz. Ya da yalnızca mevcut kabuk üzerinden girilen komutun oluşturduğu tüm işlemleri tek seferde yönetmek istiyorsanız da iş numarasını kullanmanız yeterlidir.

Örneğin buradaki pipeline üzerindeki tüm işlemleri tek seferde sonlandırmak istersem bu konsol üzerinden kill %1 komutunu girmem yeterli. Eğer tüm işlemleri değil de yalnızca sleep 2222 işlemini sonlandırmak istersem de bu işlemin işlem numarasını veya pkill sleep 2222 komutu ile işlemi ismini girmem yeterli. Buradaki tüm mesele ihtiyacınızın ne olduğuyla ilgili.

Umarım yeterince açıklayıcı olabilmiştir. Eğer iş ile işlem arasındaki farkı doğru şekilde öğrenebildiyseniz ne zaman işlem numarasını ne zaman da iş numarasını kullanacağınızı artık biliyorsunuz.

Şimdi iş tablosunun etkili kullanımı için birkaç temel işlevden daha bahsedelim.

İşlemlerin iş tablosu üzerinden yönetilebilmesi için elbette işlemlerin ya arkaplanda başlatılmış olması ya da daha sonra durdurulup arkaplana alınması gerekiyor. Aksi halde mevcut kabuğa yeni komutlar giremeyeceğimiz için iş tablosundaki işlemleri yönetmemiz mümkün olmaz. İşlemler arkaplanda başlatıldığı için de aslında doğrudan mevcut kabuğa işlemin durumu hakkında bir çıktı basılmıyor. Yalnızca ilgili işin durum değişiklik bilgisi konsola çıktı olarak bastırılıyor. Ben denemek için yeni bir konsol açıyorum. Örnek olması için kabuğuma sleep 111& şeklinde yazıp onaylıyorum. Bakın işlem arkaplanda başlatıldığı için iş tablosundaki numarası ve işlem numarası konsola çıktı olarak bastırıldı. Neticede işlem arkaplanda çalıştığı için bu bilgiler bizim için faydalı olabilir. Komutun başlangıcında aldığımız çıktı dışında bir de komutun tamamlandığı yani tüm işlemlerinin bittiği durumda da konsola çıktı bastırılarak haberdar ediliyoruz. Neticede işlem arkaplanda çalıştığı için unutmuş da olabiliriz. Arkaplandaki işin bittiğini konsola en son girdiğimiz komutun ardından öğrenebiliriz. Sleep işleminin sonlandığından emin olmak istiyorum onun için biraz bekleyebiliriz. Arkaplandaki sleep işlemi sonlanmıştır. Eğer konsola herhangi bir komut girersem bu komutun çıktılarının hemen ardından sleep işleminin tamamlandığına dair çıktı bastırılacak. Hatta komut girmeme bile gerek yok. Bir alt satıra geçmek için enter tuşunu kullandığımda görebildiğiniz gibi konsola sleep işleminin sonlandığını bildiren çıktı otomatik olarak bastırılıyor. Bu çıktısının bastırılmasını sağlayan da iş yönetim mekanizmasıdır. Bakın iş numarası ve sonlandırılan işin komut karşılığı çıktı olarak konsola bastırılmış. Bu sayede arkplandaki işler sona erdiğinde haberimiz oluyor. Görebildiğiniz gibi iş tablosu ve iş yönetimi mekanizması kabuk üzerinden işlemlerin yönetimini oldukça kolay hale getiriyor.

Hatta iş yönetiminde kullanabileceğimiz birkaç kısayol da bulunuyor. Mevcut kabuktaki görevleri belirtirken yüzde işareti `%` kullandığımızı fark etmişsinizdir. Bu işaret işi belirtme anlamında yani "jobspec" olarak anılır. Bu işaretin ardından iş tablosundaki iş numarasını yazabileceğimiz gibi doğrudan komutu yazarak da ilgili işi hedef gösterebiliriz. Ben denemek için sleep 44& komutu ile yeni bir iş oluşturulmasını sağlıyorum. Bakın bu iş 1 numaralı iş olarak tabloda yer alıyor. Eğer bu işi kapatmak istersem kill %1 komutunu kullanabilirim ve ayrıca kill %sleep şeklinde de yazabilirim. jobs komutu ile son durumu kontrol edelim. Bakın işlem sonlandırılmış. Yüzde işaretinden sonra yazdığım ifade iş tablosundaki komutlar ile eşleştiriliyor eğer uyan bir iş varsa o iş belirtilmiş oluyor. Yani yalnızca iş tablosundaki numarasıyla değil komutların kendisi ile de temsil edilmesi mümkündür. Bu kullanımda eğer girdiğiniz komut benzersiz bir komutsa yani halihazırda çalışmakta olan başka bir iş aynı komutu kullanmıyorsa komutun yalnızca bir kısmını yazmanız yeterli. Ben denemek için yine sleep 44& komutunu giriyorum. Şimdi işi sonlandırmak üzere kill %sl şeklinde bile yazsam bu işlem sonlandırılacak. Enter ile yeni satıra geçtiğimizde işlemin sonlandırılığını görebiliyoruz. Eğer aynı komut birden fazla işte kullanılmış olsaydı elbette ilgili komutun tamamını özellikle belirtmemiz gerekiyor. Ben örnek olması için bu kez sleep 333 & sleep 444& şeklinde komutumu giriyorum. jobs komutu ile kontrol edelim. Bakın sleep komutu ile oluşturduğumuz iki iş de tabloya eklenmiş. Ben şimdi kill %sl şeklinde komutumu girmek istiyorum. Bakın belirsiz jobspec şeklinde hata aldık. Çünkü aynı ifade ile başlayan iki komutta iş tablosunda bulunuyor. Bunun yerine tam olarak hedef göstermek istediğimiz işi belirtmemiz gerekiyor. Yani örneğin kill "%sleep 333" şeklinde komutumuzu girebiliriz. Komut içinde boşluk karakteri olduğu için elbette bu komutu tırnak içinde yazmamız gerekiyor. Jobs komutu ile kontrol ettiğimizde sleep 333 işleminin sonlandırılığını görebiliyoruz. Sizler de bu şekilde işlerin komutlarını kullanarak ilgili işi hedef gösterebilirsiniz.

Komut dışında ayrıca birkaç kısayol karakteri de bulunuyor. Öncelikle yeni bir konsol açıp eskisini kapatalım. Şimdi ben örnek olması için sleep 111& sleep 222& sleep 333& sleep 444& şeklinde komutumu giriyorum. jobs komutu ile de teyit edebildiğimiz üzere dört farklı iş tabloya eklendi. Eğer ben en son eklenmiş olan yani sondaki işi hedef göstermek istersem çift yüzde işareti kullanabilirim. Yani örneğin en son işi duraklatmak için kill -STOP %% şeklinde sinyal gönderebilirim. Normale bu işlemin iş tablosundaki numarasını belirtmem gerekiyor ancak en son işlemi tanımlamak için yüzde işaretini de kullanabiliyoruz. Jobs komutunu kullanarak işleri listeleyelim. Bakın en sondaki iş kullanmış olduğum yüzde işareti ile temsil edilebildiği için durudurulmuş oldu. Ayrıca buradaki çıktılarda da görebildiğiniz gibi artı ve eksi işaretleri ile en sondaki ve sondan bir önceki işlemi de kısayoldan hedef gösterebiliyoruz. Yani örneğin bu listede eksi işaretinin yer aldığı sondan bir önceki işi durdurmak için kill -STOP %- şeklinde komut girmem yeterli. Jobs ile tekrar listeleyelim. Bakın bu işlem de durdurulmuş. Açıkçası ben sondaki iş için çift yüzde işareti ve doğrudan ilgili işin numarası dışında diğer kısayolları pek kullanışlı bulmadığım için neredeyse hiç kullanmıyorum. Ancak yine de farklı kaynaklar üzerinde karşılaştığınızda şaşırmamanız için de eklemek istedim. Sizin için hangi kullanım metodu kolay geliyorsa onu kullanmakta özgürsünüz.

Hazır job spec yani % işaretinin işler üzerindeki kullanımından bahsetmişken kısaca arkaplana alma ve arkaplandaki işleri de ön plana almadan jobspec özelinde bahsedelim istiyorum. Daha önce işlem numarası üzerinden işlemleri arkaplana veya önplana örnekleri yapmıştık. Şimdi de iş tablosunu kullanarak yapalım.

Örneğin diyelim kim ben sleep 111 | sleep 222| sleep 333 şeklinde komut verdim. Bu komut görebildiğiniz gibi önplanda çalışıyor dolayısıyla kabuğa yeni emirler veremiyorum. Bu duruma çözüm olarak bu işi arkaplana alabilirim. Bunun için öncelikle ctrl z ile bu işi duraklatalım. Bakın bu iş duraklatıldı. Şimdi bu işin arkaplanda çalışmaya devam edebilmesi için tek yapmamız gereken bg  komutunun ardından iş numarasını girmek. Ben en son komut olduğu için iş numarası yerine kısayoldan bg %% şeklinde komutumu giriyorum. Jobs komutu ile işin durumunu kontrol edelim. Bakın iş arkaplanda çalışmaya devam ediyor. Benzer şekilde arkaplandaki işi ön plana almak için fg %% şeklinde komut girmem de yeterli. Bakın işlem tekrar ön planda çalışmaya başladı. 

Yani mevcut kabuk üzerinden çalıştırdığınız tüm işlemleri dilerseniz iş kontrol tablosu üzerinden sorunsuzca ve büyük bir kolaylıkla yönetebilirsiniz. Ben henüz örnek vermedim ama disown komutunu iş tablosundaki işler için de kullanabiliyoruz. Ben temiz bir konsol üzerinden çalışmak için yeni bir konsol açıyorum ve bu konsolu da kapatıyorum. Şimdi örnek olması için gedit & komutu ile gedit aracını arkaplanda başlatmak istiyorum. Aracım açıldı. Eğer konsol penceresini kapatırsam bu aracın da kapanacağını biliyoruz. Bunu önlemek için disown komutunun ardından bu aracın işlem numarasını ya da iş numarasını belirtebiliriz. Ben iş numarasını kullanmak istediğim için disown %1 şeklinde komutu girmem yeterli. Zaten mevcut kabuk üzerindeki ilk iş olduğu için %1 de kullanabilirim %% de kullanabilirim. Neticede gedit aracını iş tablosundaki numarası üzerinden yani jobspec kullanarak hup kapatma sinyaline karşı korumuş oldum. Teyit etmek için konsolu kapatalım. Bakın gedit aracı hala çalışmaya devam ediyor. 

Sanırım artık işlem kontrolü ve iş kontrolü arasındaki farkları ve kullanım örneklerini temel seviyede yeterince ele aldık. Mevcut konsol üzerinden başlatılan işlemleri kolayca yönetmek için iş kontrolünü kullanabileceğinizi artık biliyorsunuz. 

Ayrıca grafiksel arayüzde tıpkı windows üzerindeki görev yöneticisi gibi işlem yönetim aracı da bulunuyor. Ubuntu üzerinde bu araç system montior olarak geçiyor. Dilerseniz bu araç üzerinden de çalışmakta olan işlemleri görüntüleyip gerektiğinde sağ tıklayarak durdurmak devam ettirmek sonlandırmak veya öldürmek gibi işlemleri de yerine getirebilirsiniz. Ayrıca dosya konumunu açmak veya özellikleri hakkında bilgi alıp işlem önceliğini değiştirmek gibi diğer seçenekleri de kullanabilirsiniz. Yani aslında windows üzerinden alışık olduğunuz görev yöneticisine benzer bir araç. Yani kısa sürece kurcalama ile keşfedebilirsiniz. Bakın burada sistem kaynakları da gösteriliyor. CPU ram ve ağ kullanımı hakkında grafiksel arayüz üzerinden bilgi almak için bu aracı da kullanabilirsiniz. Diğer sekmede kısaca dosya sistemleri hakkında da bilgi sunuluyor. Özetle isminde de yer aldığı şekilde sistemi monitöre etmek için kullanabileceğiniz güzel bir araç. Eğer sizin kullanmakta olduğunuz dağıtımda bu tür bir araç yoksa repolardan task manager ya da system monitor benzeri araştırmalar yaparak bu gibi grafiksel arayüze sahip araçlara ulaşabilirsiniz. Zaten yeni araçları nasıl bulup sisteminize ne şekilde kurabileceğinizi biliyorsunuz. Ben grafiksel arayüze pek takılmak istemiyorum. Grafiksel arayüzü bir kenara bırakıp işlem önceliği kavramından da bahsedek işlem ile ilgili bu bölümü noktalamak istiyorum. Ben komut satırı üzerinden ele alacağım ancak grafikse arayüzde bir işleme sağ tıkladığımızda bu işlemin de işlem önceliğini değiştirebiliyoruz gördüğünüz gibi.

# İşlem Önceliğinin Değiştirilmesi | nice ve renice

İşlem önceliğini nasıl değiştirilebileceğimize değinmeden önce işlem önceliğinin ne ifade ettiği ve bizim için neden önemli olabileceği hakkında genel bilgi sahibi olalım.

CPU ZAMANLAMA

Elbette derinlemesine teknik ayrıntılara sistem yöneticisi olarak bizim ihtiyacımız yok. Yalnızca işlemcilerin aynı anda nasıl birden çok işlemi çalıştırabildiğinden çok kısaca bahsedebiliriz. Temelde işlemciler sahip oldukları çekirdek sayısınca aynı anda paralel olarak işlemleri yürütebilirler. Yürütülmesi gereken işlem sayısı çekirdek sayısını aştığında ise çoklu görev sağlamak için gelişmiş değiştirme mekanizmaları kullanılarak işlemler arasında çok hızlı geçiş yapılır. Yani örneğin işlemcinin tek çekirdeği olsa dahi birden çok işlemi çalıştırabiliriz. Bu programlar bize göre aynı anda çalışıyormuş gibi görünür ancak cpu üzerinde kesik kesik şekilde sırasıyla tüm işlemler yürütülür. İşlemlerin yürütülmesi sırasındaki kesintiler bizlerin fark edemeyeceği hızda gerçekleştiği için bizler tüm işlemlerin aynı anda yürütüldüğünü sanarız. Hangi işlemin hangi sırada işlemci tarafından yürütüleceğine de işlemci zamanlayıcısı karar verir, bu doğrultuda işlemler sıralanır. 

Neticede sistem üzerinde aynı anda çalışması gereken bir çok işlem olduğu için bu yaklaşım tüm işlemlerin öncelik sıralamasına göre sırasıyla parça parça işlenmesini sağlar. Böylelikle işlemci tek çekirdekli dahi olsa sistem üzerindeki birden çok işlemin sorunsuzca çalışmaya devam etmesi sağlanmış olur. Yani örneğin 3 işlemin tek çekirdek üzerinden işlenmesine örnek olarak bu basit soyutlama diyagramına bakabiliriz. 

![]({{ site.url}}/egitimserisi/img/18-%20I%CC%87s%CC%A7le%2075bff/Untitled%205.png)

Üç işlem de bize aynı anda çalışıyor gibi görünmesine karşın işlemci üzerinde sırasıyla kesik kesik işlenir. İşte bizler işlemlerin önceliklerini değiştirdiğimizde işlemci üzerindeki işlenme önceliğini öne almış oluyoruz. Bu sayede ilgili işlem çok daha kısa sürede işlemci kaynağına erişip işini yerine getirebiliyor. Gerçek hayatta da olduğu gibi işlerimizi küçük parçalara bölüp aynı gün içinde birden fazla işi tamamlayabiliriz. Ve bu parçalara böldüğümüz işleri yerine getirirken elbette önem sıralamasına göre önce halletmeye gayret ederiz. İşte işlemci üzerinde de benzeri yaklaşım söz konusu. 

Dediğim gibi aslında tüm yapı bu kadar basit değil ama bizim temelde bilmemiz gereken işleyiş bu şekilde. Eğer önemli bir işlemin bir an önce halledilmesi gerekiyorsa o işleme öncelik tanıyabiliyoruz. Örneğin sisteminizin yedeğini alırken acil olarak bir işlem çalıştırmanız gerekirse, acil olan işlemi çalıştırmak için uzun sürecek olan yedekleme işleminin bitmesini beklemezsiniz heralde. İşte bu gibi durumlar için nice ve renice komutunu kullanarak işlemlerin önceliklerini değiştirebiliyoruz.

Normalde işletim sistemi çekirdeği tarafından bir görevin zamanlanması için işlemin öncelik değeri dikkate alınır. Yani tüm işlemler çalıştırılma önceliklerine göre sıralanırlar. Linux'ta sistem öncelikleri 0 ile 139 arasındadır. Buradaki sıralamayı liste gibi büşünebilirsiniz elbette 0 en öncelikli sıradır dolayısıyla işlem öncelik sayısı ne kadar küçük ise işlem o kadar önceliklidir.

Linux üzerinde gerçek zamanlı işlemler için 0 ile 99 arasında ve kullanıcılar için de 100 ile 139 arasında öncelik tanımlanabilir. Yani 0 ile 139 aralığı olmasına karşın bizlerin kullanıcılar olarak çalıştırdığımız işlemler için belirleyebileceği aralık 100 ile 139 değerleri arasındadır. Bunları da konsol üzerinde kolayca sıralayabilmek için nice yapısını kullanıyoruz. 

Yani aslında Linux üzerinde kullanıcıların belirleyebileceği işlem önceliği değeri nice değeri olarak ifade ediliyor. Nice değer aralığı -20 ila +19'dur, burada -20 en yüksek, 0 varsayılan ve +19 en düşüktür. Bekleyin hemen kafanız karışmasın. Buradaki nice ifadesi kibar olmakla ilişkilendirilmiştir. Bir işlem kibarsa sırasına daha öncelikli işlemlere verebilir. Bu bağlamda nice değeri pozitif olan işlemler düşük önceliklidir çünkü kibar oldukları için sıralarını daha öncelikli işlemlere verirler. Eğer bir işlem kibar değilse herkesin önüne geçmek ister. Bu sebeple nice değeri negatif olan işlemler işlem sırasında öne geçerek daha öncelikli işlem olarak yürütülürler. Örneğin ben +19 nice değeri tanımlarsam bu işlem çok kibar olduğu için en son sıra olan 139. işlem öncelik sırasında olur. Eğer bu işleme bir nice tanımlaması yapmazsam bu işlem 120. öncelik sırasında olur. Eğer bu işleme -20 nice değeri ile kaba olmasını söylersem varsayılan sırası olan 120. sırasından 20 sıra önce alınarak 100. işlem sırasında olur. Bu değer de kullanıcı olarak bizim işlemleri öncelikleyebileceğimiz aralığın sınırıdır zaten. 

İşte nice kavramı buradan geliyor. Umarım yeterince açıklayıcı olabilmişimdir.

Normalde bir işlemi başlatmadan önce bu işlemin öncelik sırasını nice komutu ile belirtmemiz gerekiyor. Eğer bir işlem halihazırda çalışıyorsa nice komutu ile önceliğini değiştiremeyiz. Çalışmakta olan işlemlerin önceliğini değiştirmek için de renice komutunu kullanıyoruz. Elbette kullanımlarını en iyi uygulamalar üzerinden anlayabiliriz. Ben örneklerin açık olması sürekli aynı şekilde çalışacak bir betik dosyası oluşturmak istiyorum. Yani uygulamalar sırasında sürekli aynı şekilde çalışan bir işlemimiz olacak. nano [islem.sh](http://islem.sh) komutu ile dosyamı açıyorum.

Dosyamın başına #! /bin/bash şeklinde yazıyorum. Bu ifade sayesinde bu dosya açıldığında bash ile çalıştırılacak. Dosyanın çalıştırılacağı ortamı belittik. Şimdi de bu dosya çalıştığında biz durduruna kadar sürekli işlemciyi kullanması için sonsuz bir döngü başlatalım. Ben sonsuz döngü oluşturmak için 

while true;

do

:

done

Şeklinde yazıyorum. Buradaki while true ifadesi döngünün sonsuza kadar ilerlemesini saplayacak çünkü döngünün koşulu her zaman true ifadesini döndürmeye devam ediyor olacak. do komutunun altında belirttiğim iki nokta üst üste işareti ise hiç bir şey yapma anlamına geliyor. done ifadesi de bu döngüyü bitiriyor. Bu şekilde true ifadesi ile bu döngü biz işlemi sonlandırana kadar tekrar tekrar çalıştırılıyor olacak. Bu da işlemcinin tüm kaynaklarının kullanılması demek oluyor. Dosyamızı kaydedip kapatalım. Tamamdır, şimdi de bu betik dosyasının sorunsuzca çalıştırılabilmesi için `chmod +x [islem.sh](http://islem.sh)` komutu ile dosyamıza çalıştırma yetkisi verelim. Tamamdır artık test için kullanacağımız betik dosyamız tamamen hazır.

Ben testlere geçmeden önce son olarak testlerin daha anlaşılır olabilmesi için sanal işletim sistemimin işlemci sayısını bire düşürmek istiyorum. Çekirdek sayısı bir olduğunda tüm işlemler tek bir işlemci çekirdeği üzerinde kesik kesik yürütüleceği için işlem önceliğinin etkilerini çok daha net görebiliriz. Bunun için sanal makinemi kapatıyorum. Sanal makinem kapandı. Şimdi sağ tıklayıp ayarları açalım. Buradan sistem sekmesine gelelim. Buradan da işlemci sekmesine tıklayalım. Bakın buradan bu sanal sistemin kullanımına ayrılacak olan işlemci çekirdek miktarını ayarlayabiliyoruz. Ben tek çekirdek olarak ayarlayıp okey ile ayarın geçerli olmasını sağlıyorum. Eğer işlemcide birden fazla çekirdek olursa işlemler birden fazla çekirdekte aynı anda paralel olarak yürütüleceği için işlem önceliğinin farkını oluşturduğumuz basit betik dosyası ile göremeyebiliriz. Bu sebeple yalnızca bu örnek için işlemci çekirdeği sayısını bire düşürdüm. Normalde sanal makinenizin performanslı şekilde çalışabilmesi için mümkünde en az 2 çekirdekli olacak şekilde ayarlayın mutlaka. Yani bu ayarın yalnızca testler için yaptığımızı daha sonra tekrar eski haline getirmeniz gerektiğini lütfen unutmayın. 

Şimdi işlemci çekirdeğini bire düşürdüğümüze göre makinemizi yeniden başlatabiliriz. Makinemiz açılana kadar bekleyelim. Evet makinem açıldı ve oturumumu da açtım. Şimdi testlere geçebiliriz. Yeni bir terminal açalım. Öncelikle oluşturduğumuz betiğin ne kadar işlemci kaynağını kullandığını görebilmek adına top aracını çalıştıralım. Top aracını çalıştırmak için yeni bir konsol açıyorum ve top komutunu giriyorum. Bakın şu anda çalışmakta olan işlemlerin listesini görebiliyoruz. Şimdi betik dosyasını çalıştırmak üzere diğer konsola ./islem.sh şeklinde komutumu giriyorum. Bakın anında top aracı üzerinde bu betik dosyasının en üste yükseldiğini ve neredeyse işlemci kaynağının tamamına yakını tüketmekte olduğunu görebiliyoruz. Buradaki PR ifadesi priorty yani öncelik ifadesinin kısaltması ve ni ifadesi de nice ifadesinin kısalması. Normalde varsayılan olarak bir işlem başlatıldığında önceliği 20 nice değeri de 0 olarak gözüküyor. Çünkü buradaki işlem önceliği bir sıralama belirtir. Örneğin 20 olduğunda işlem önceliği sırasında 20. ci sırada olduğu belirtiliyor. Zaten bu sebeple nice değerinde -20 olduğunda işlem en kaba dolayısıyla en ön sıraya geçen işlem oluyor. En en sıra da 0 sırası olduğu için buradaki nice değeri -20 iken buradaki priorty yani öncelik sırası değeri de 0 oluyor.

Normalde kullanıcıların başlattıkları işlemler 20. öncelik sırasında dolayısı ile 0 nice değerine sahip oluyor.

Nitekim bakın bizim çalıştırdığımız betik dosyasının önceliği herhangi bir ayarlama yapmadığımız için bu şekilde gözüküyor. Ben ctrl c ile betik dosyasını durduruyorum. Şimdi betik dosyasını arkaplanda iki ayrı işlem olarak çalıştırıp işlemci kaynaklarının ne şekilde bölüştürüldüğünü görmek istiyorum. Bunun için ./islem.sh & ./islem.sh & şeklinde komutumu giriyorum. Bakın top aracı üzerinde her iki işlemin de işlem listesinde en üste geldiğini hemen görebiliyoruz. Üstelik neredeyse yüzde elli yüzde elli işlemci kaynaklarının tamamına yakını bu iki işlemi yürütmek için kullanıyor. Aynı önceliğe sahip oldukları için işlemci kaynaklarını neredeyse eşit olarak paylaşıyorlar. Eğer aynı şekilde üçüncü bir işlem olarak betik dosyamı çalıştırırsam yüzde 33 olacak şekilde işlemci kaynakları bu üç işlem arasında dağıtılıyor olacak. Ancak ben böyle olmasını istemiyorum. Üçüncü işlemimin daha düşük önceliğe sahip olmasını istiyorum. Bunun için üçüncü işlemi nice komutu ile işlem önceliğini önceden belirterek başlatabilirim. Ben en düşük önceliğe sahip olmasını istiyorum bunun için +19 nice değerini kullanacağım. Böylelikle bu işlem çok kibar olacak ve öncelik sırasını başka işlemlere verecek. Komutun kullanımı nice -n öncelik sayısı çalıştırılacak komut şeklindedir. Ben nice -n +19 ./islem.sh& şeklinde komutumu giriyorum. Şimdi tekrar top komutuna bakacak olursak en son çalıştırdığım betik dosyasının işlem öncelik numarası 20 nin üzerine 19 eklenerek 39 olmuş çünkü varsayılan öncelik sıralamsı 20 iken bu işlem kibarlık yaparak 19 sıra geriye düşmüştür. Dolayısıyla nice değeri de belirttiğim şekilde 19 olarak gözüküyor. Yani öncelik sıralamasını sorunsuzca tanımlayarak işlemi başlatabilmişim. Daha önemlisi bakın önceliği düşük olan işlem aynı betik dosyasını çalıştırmasına rağmen işlemcinin çok çok az bir kaynağını kullanıyor. Çünkü işlem önceliği diğer işlemlerden düşük dolayısı ile bu işleme pek fazla sıra gelmiyor. Daha çok öncelikli işlemler yürütülüyor. Tamamdır işlem önceliğini nice komutu ile nasıl tanımlayabileceğimizi gördük peki var olan işlemlerin önceliklerini nasıl değiştirebiliriz ?

İşte bu noktada da renice komutunu kullanabiliriz. Aynı şekilde nice değerini renice -n işlem öncelik sayısı ve işlem numarası şeklinde belirmemiz yeterli. Ben denemek için betik dosyasın çalıştırıldığı ilk işlemin nice değerini +10 olarak belirlemek istiyorum. Bunun için renice -n +10 işlem numarası şeklinde komutumu giriyorum. Bakın işlemin öncelik durumunun değiştiğini çıktı olarak aldık ve anında top komutunun çıktılarına da yanısıdı. Artık bu işlemin nice değeri +10 oldu ve önceliği 30. sıraya gerilemiş oldu. Bu sayede işlemci kaynaklarının kullanımı da azaldı görebildiğiniz gibi. Ben son olarak düşük öncelikli olan işlemin önceliğini yükseltmek yani eski bir nice değeri vermek istiyorum. Bunun için en son çalıştırdığım betik dosyasının nice değerini -20 yapmak istiyorum. Ancak unutmayın önceliği düşürmek için root yetkisi gerekmiyorken yükseltmek için root yetkileri gerektirir.  Denemek için sudo komutu olmadan renice -n -20 işlem numarası şeklinde komutumuzu girelim. Bakın yetki hatası aldık çünkü eksi nice değeri vererek bu işlemin önceliğini arttımayı denedik. Bu da daha fazla işlemci kaynağının kullanılabilmesi demek olduğu için root yetkileri dahilinde gerçekeştirilmelidir. Hemen sudo !! komutu ile en sonra komutu root yetkileri ile çalıştıralım. Bakın bu kez herhangi bir hata almadık ve öncelik değerinin değiştiği konusunda konsola çıktı bastırıldı. Top aracının çalıştığı konsola baktığımızda ise bu son işlemin önceliğinin arttığını ayni öncelik değerinin 0 nice değerinin ise -20 olduğunu görebiliyoruz. Ve elbette bu doğrultuda işlemci kaynağının büyük çoğunluğu da artık bu işlem tarafından tüketiliyor.

Ben örneklerimde sonuçların bariz olabilmesi için hep -20 +19 gibi nice değerleri kullandım ancak sizler elbette istediğiniz ara değeri kullanabiliriz. Örneğin işlem önceliğini düşürmenin yani nice değerini yükseltmenin yetki gerektirmediğini söylemiştim. Hemen denemek için nice değeri -20 olan yani en öncelikli olan işlemin öncelik durumunu -10 nice derecesine yükseltmek için renice -n -10 işlem numarası şeklinde komutumuzu girelim. Bakın -20 den -10 nice derecesine yükselttiğim yani aslında işlem önceliğini düşürdüğüm için herhangi bir yetki hatası da almadım. İşte sizler de bu şekilde duruma göre işlemleri henüz başlatmadan veya başlattıktan sonra önceliklerini değiştirebilirsiniz. Ayrıca dikkatinizi çekmek istediğim detay sistem tarafından başlatılan diğer işlemlerin öncelik sıralarının daha düşük veya daha yüksek olduğunu top gibi işlem izleme araçlarının çıktılarında görebilirsiniz. Bu gördüğünüz değerler sistem tarafından belirtlenmiş olan değerler olup, bizim kullanıcı olarak 100 ile 139 yani 100 ü milat kabuk edip -20 ile +19 nice aralığında işlem önceliği belirleme imkanımız bulunuyor.

Ayrıca dilersek tek bir işlem yerine spesifik olarak bir kullanıcının çalıştırdığı tüm işlemlerin işlem önceliğini de değiştirebiliriz. Ben denemek için kendi hesabımı kullanmak istiyorum. Elbette kullanıcıların işlemlerine müdahale ettiğim için sudo komutu başta olacak şekilde yani root yetkileri ile bu işlemi gerçekleştirmemiz gerekiyor.  İşlemleri takibi noktasında htop aracını kullanıp işlem önceliğine göre sıralayarak çıktıları daha net takip edebiliriz. htop aracını çalıştıralım. nice değerinin bulunduğu sekmeye tıklayarak işlemlerin bu değere göre sıralanmasını sağlayabiliriz. Bakın şu anda çoğu işlemin nice değeri 0 olarak gözüküyor. 

Ben örnek olması için kendi kullanıcım tarafından başlatılan tüm işlemlerin nice değerini +1 olarak ayarlamak yani işlem önceliğini düşürmek istiyorum. Bu sayede değişikliği de htop çıktılarında daha rahat görebiliriz. Bunun için sudo renice -n +1 -u taylan şeklinde yazıyorum. Bakın buradaki -u seçeneğinin ardından bu işlem önceliğinin hangi kullanıcı hesabı genelinde geçerli olması gerektiğini belirtmiş oluyorum. Normalde işlem numarasını giriyorduk buradaki -u seçeneği ile doğrudan kullanıcı hesabını hedef göstermiş oluyoruz. Bakın htop aracında bir anda pek çok işlemin nice değeri 1 olarak değişti çünkü kendi kullanıcı hesabımdaki tüm işlemlerin +1 nice değerini almasını sağladım. Böylelikle tek bir işlem yerine kullanıcıların çalıştırdıkları tüm işlemlerin önceliklerini de nasıl değiştirebileceğimizi görmüş olduk.

En nihayetinde işlemler hakkında bahsetmemiz gereken temel anlatımın sonuna gelmiş olduk. Bir sonraki bölümde çalışma seviyeleri ve servislerden bahsederek devam ediyor olacağız.

Bol bol pratik yapmayı unutmayın!

[https://medium.com/@chetaniam/a-brief-guide-to-priority-and-nice-values-in-the-linux-ecosystem-fb39e49815e0](https://medium.com/@chetaniam/a-brief-guide-to-priority-and-nice-values-in-the-linux-ecosystem-fb39e49815e0)

TOP VE HTOP ARAÇLARINDAN BAHSET

Birden fazla işlem aynı grupta bulunduğunda işlem gurubu yani gpid ortak oluyor. ve bu id de bu işlem gurubunun liderinin id sinden geliyor. birden fazla işlem gurubunu da session olarak geçen mevcut oturum üzerinden yönetebiliyoruz. bir konsolda aynı anda yalnızca bir oturum yönetilebileceği için jobs kontrol mevcut oturumdaki işlemleri veya işlem gruplarını yönetmek için kullanıyor.


![]({{ site.url}}/egitimserisi/img/18-%20I%CC%87s%CC%A7le%2075bff/Untitled%206.png)

ps çıktısındaki kısaltmalar ve anlamları aşağıdaki gibidir.

[Untitled](https://www.notion.so/fbc26365c088449eb219865afec70ef0)
